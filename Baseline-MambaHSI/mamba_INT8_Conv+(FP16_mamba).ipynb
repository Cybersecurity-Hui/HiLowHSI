{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858969ef-7551-41d6-99a2-a7d98572a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from mamba_ssm import Mamba\n",
    "import math\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from torchvision import models,transforms\n",
    "import utils.data_load_operate as data_load_operate\n",
    "from utils.Loss import head_loss,resize\n",
    "from utils.evaluation import Evaluator\n",
    "from utils.HSICommonUtils import normlize3D, ImageStretching\n",
    "from utils.setup_logger import setup_logger\n",
    "from utils.visual_predict import visualize_predict\n",
    "from PIL import Image\n",
    "from calflops import calculate_flops\n",
    "import cv2\n",
    "from typing import Tuple,Union\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.ao.quantization import QuantStub, DeQuantStub, prepare_qat, get_default_qat_qconfig, HistogramObserver, PerChannelMinMaxObserver\n",
    "import torch.quantization as tq\n",
    "from torch.quantization import QConfig, default_observer, default_per_channel_weight_observer\n",
    "import torch.nn.quantized as nnq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db8929a0-087f-41a6-bac7-de9dc58ac015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeMamba(nn.Module):\n",
    "    def __init__(self,channels, token_num=8, use_residual=True, group_num=4):\n",
    "        super(SpeMamba, self).__init__()\n",
    "        self.token_num = token_num\n",
    "        self.use_residual = use_residual\n",
    "\n",
    "        self.group_channel_num = math.ceil(channels/token_num)\n",
    "        self.channel_num = self.token_num * self.group_channel_num\n",
    "\n",
    "        self.mamba = Mamba( # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "                            d_model=self.group_channel_num,  # Model dimension d_model\n",
    "                            d_state=16,  # SSM state expansion factor\n",
    "                            d_conv=4,  # Local convolution width\n",
    "                            expand=2,  # Block expansion factor\n",
    "                            )\n",
    "\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.GroupNorm(group_num, self.channel_num),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "    def padding_feature(self,x):\n",
    "        B, C, H, W = x.shape\n",
    "        if C < self.channel_num:\n",
    "            pad_c = self.channel_num - C\n",
    "            pad_features = torch.zeros((B, pad_c, H, W)).to(x.device)\n",
    "            cat_features = torch.cat([x, pad_features], dim=1)\n",
    "            return cat_features\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_pad = self.padding_feature(x)\n",
    "        x_pad = x_pad.permute(0, 2, 3, 1).contiguous()\n",
    "        B, H, W, C_pad = x_pad.shape\n",
    "        x_flat = x_pad.view(B * H * W, self.token_num, self.group_channel_num)\n",
    "        x_flat = self.mamba(x_flat)\n",
    "        if x_flat.dtype == torch.float16:\n",
    "            # 如果是 float16，则转换为 float32\n",
    "            x_flat = x_flat.to(torch.float32)\n",
    "        x_recon = x_flat.view(B, H, W, C_pad)\n",
    "        x_recon = x_recon.permute(0, 3, 1, 2).contiguous()\n",
    "        x_proj = self.proj(x_recon)\n",
    "        if self.use_residual:\n",
    "            return x + x_proj\n",
    "        else:\n",
    "            return x_proj\n",
    "\n",
    "\n",
    "class SpaMamba(nn.Module):\n",
    "    def __init__(self,channels,use_residual=True,group_num=4,use_proj=True):\n",
    "        super(SpaMamba, self).__init__()\n",
    "        self.use_residual = use_residual\n",
    "        self.use_proj = use_proj\n",
    "        self.mamba = Mamba(  # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "                           d_model=channels,  # Model dimension d_model\n",
    "                           d_state=16,  # SSM state expansion factor\n",
    "                           d_conv=4,  # Local convolution width\n",
    "                           expand=2,  # Block expansion factor\n",
    "                           )\n",
    "        if self.use_proj:\n",
    "            self.proj = nn.Sequential(\n",
    "                nn.GroupNorm(group_num, channels),\n",
    "                nn.SiLU()\n",
    "            )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_re = x.permute(0, 2, 3, 1).contiguous()\n",
    "        B,H,W,C = x_re.shape\n",
    "        x_flat = x_re.view(1,-1, C)\n",
    "        x_flat = self.mamba(x_flat)\n",
    "        if x_flat.dtype == torch.float16:\n",
    "            # 如果是 float16，则转换为 float32\n",
    "            x_flat = x_flat.to(torch.float32)\n",
    "        x_recon = x_flat.view(B, H, W, C)\n",
    "        x_recon = x_recon.permute(0, 3, 1, 2).contiguous()\n",
    "        if self.use_proj:\n",
    "            x_recon = self.proj(x_recon)\n",
    "        if self.use_residual:\n",
    "            return x_recon + x\n",
    "        else:\n",
    "            return x_recon\n",
    "\n",
    "\n",
    "class BothMamba(nn.Module):\n",
    "    def __init__(self,channels,token_num,use_residual,group_num=4,use_att=True):\n",
    "        super(BothMamba, self).__init__()\n",
    "        self.use_att = use_att\n",
    "        self.use_residual = use_residual\n",
    "        if self.use_att:\n",
    "            self.weights = nn.Parameter(torch.ones(2) / 2)\n",
    "            self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "        self.spa_mamba = SpaMamba(channels,use_residual=use_residual,group_num=group_num)\n",
    "        self.spe_mamba = SpeMamba(channels,token_num=token_num,use_residual=use_residual,group_num=group_num)\n",
    "\n",
    "    def forward(self,x):\n",
    "        spa_x = self.spa_mamba(x)\n",
    "        spe_x = self.spe_mamba(x)\n",
    "        if self.use_att:\n",
    "            weights = self.softmax(self.weights)\n",
    "            fusion_x = spa_x * weights[0] + spe_x * weights[1]\n",
    "        else:\n",
    "            fusion_x = spa_x + spe_x\n",
    "        if self.use_residual:\n",
    "            return fusion_x + x\n",
    "        else:\n",
    "            return fusion_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0364f8fd-f168-4f94-b71b-a4300ae6b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化图片保存\n",
    "def vis_a_image(gt_vis,pred_vis,save_single_predict_path,save_single_gt_path,only_vis_label=False):\n",
    "    visualize_predict(gt_vis,pred_vis,save_single_predict_path,save_single_gt_path,only_vis_label=only_vis_label)\n",
    "    visualize_predict(gt_vis,pred_vis,save_single_predict_path.replace('.png','_mask.png'),save_single_gt_path,only_vis_label=True)\n",
    "\n",
    "# 设置种子使得所有参数的初始化相同，能够复现\n",
    "def setup_seed(seed):\n",
    "    # PyTorch CPU随机种子\n",
    "    torch.manual_seed(seed)\n",
    "    # 所有GPU的随机种子\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # Python哈希种子（影响字典等数据结构的行为）\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # NumPy随机种子\n",
    "    np.random.seed(seed)\n",
    "    # Python内置随机种子\n",
    "    random.seed(seed)\n",
    "    # 启用确定性算法（降低性能但保证可重复）\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # 关闭自动优化（固定卷积算法选择）\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 函数返回解析后的参数对象args，这样主程序可以通过args.dataset_index等方式访问这些参数的值\n",
    "def get_parser():\n",
    "    # 创建参数解析器实例\n",
    "    parser = argparse.ArgumentParser(\n",
    "        # 添加这两行配置\n",
    "        allow_abbrev=False,\n",
    "        add_help=False\n",
    "    )\n",
    "    # 添加参数定义\n",
    "    parser.add_argument('--dataset_index', type=int, default=2)      # 数据集编号\n",
    "    parser.add_argument('--data_set_path', type=str, default='./data') # 数据集路径\n",
    "    parser.add_argument('--work_dir', type=str, default='./')        # 工作目录\n",
    "    parser.add_argument('--lr', type=float, default=0.0003)         # 学习率\n",
    "    parser.add_argument('--max_epoch', type=int, default=200)       # 最大训练轮次\n",
    "    parser.add_argument('--train_samples', type=int, default=30)    # 每类训练样本数\n",
    "    parser.add_argument('--val_samples', type=int, default=10)      # 每类验证样本数\n",
    "    parser.add_argument('--exp_name', type=str, default='RESULT_INT8_Conv')     # 实验名称\n",
    "    #parser.add_argument('--exp_name', type=str, default='RESULT_INT8_Conv_FP16_Mamba')     # 实验名称\n",
    "    parser.add_argument('--record_computecost', type=bool, default=True) # 是否记录计算成本\n",
    "    # 解析命令行参数\n",
    "    args, _ = parser.parse_known_args()  # 改为解析已知参数\n",
    "    return args\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "args = get_parser()\n",
    "\n",
    "record_computecost = args.record_computecost\n",
    "exp_name = args.exp_name\n",
    "dataset_index = args.dataset_index\n",
    "max_epoch = args.max_epoch\n",
    "learning_rate = args.lr\n",
    "work_dir = args.work_dir\n",
    "\n",
    "#seed_list = [0,1,2,3,4,5,6,7,8,9]  \n",
    "seed_list = [0] \n",
    "\n",
    "num_list = [args.train_samples, args.val_samples]\n",
    "net_name = 'MambaHSI'\n",
    "\n",
    "paras_dict = {'net_name':net_name,'dataset_index':dataset_index,'num_list':num_list,\n",
    "              'lr':learning_rate,'seed_list':seed_list}\n",
    "\n",
    "\n",
    "                      # 0        1         2         3        4\n",
    "data_set_name_list = ['UP', 'HanChuan', 'HongHu', 'Houston']\n",
    "data_set_name = data_set_name_list[dataset_index]\n",
    "\n",
    "if data_set_name in ['HanChuan','Houston']:\n",
    "    split_image = True\n",
    "else:\n",
    "    split_image = False\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((2048, 1024)),  # 调整图像尺寸（已注释）\n",
    "    transforms.ToTensor(),              # 核心转换：将图像转为张量，将 PIL 图像或 NumPy 数组转换为张量，并自动归一化像素值到 [0,1] 范围\n",
    "    # 标准化操作（以下两项均被注释）\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    # transforms.Normalize(mean=[123.6750, 116.2800, 103.5300], std=[58.395, 57.120, 57.3750]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "689af1fe-c64b-40ea-9209-b5d6ecaf4450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_better_qconfig():\n",
    "    \"\"\"创建更优的量化配置\"\"\"\n",
    "    activation_observer = torch.ao.quantization.MovingAverageMinMaxObserver.with_args(\n",
    "        dtype=torch.qint8,\n",
    "        qscheme=torch.per_tensor_symmetric,  # 使用对称量化\n",
    "        reduce_range=False,\n",
    "        averaging_constant=0.01  # 添加移动平均\n",
    "    )\n",
    "    \n",
    "    weight_observer = torch.ao.quantization.MinMaxObserver.with_args(\n",
    "        dtype=torch.qint8,\n",
    "        qscheme=torch.per_tensor_symmetric,  # 使用对称量化\n",
    "        reduce_range=False\n",
    "    )\n",
    "    \n",
    "    return torch.ao.quantization.QConfig(\n",
    "        activation=activation_observer,\n",
    "        weight=weight_observer\n",
    "    )\n",
    "class Low_Model(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, index=True):\n",
    "        super().__init__()\n",
    "        self.index = index\n",
    "        self.quant = QuantStub()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding\n",
    "        )\n",
    "        self.dequant = DeQuantStub()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_or = x\n",
    "        x = self.quant(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.dequant(x)\n",
    "        # if self.index:\n",
    "        #     return x + x_or\n",
    "        return x\n",
    "    \n",
    "    def set_qconfig(self):\n",
    "        # 获取高精度配置\n",
    "        high_precision_qconfig = create_better_qconfig()\n",
    "        \n",
    "        # 为不同层设置不同的量化配置\n",
    "        self.conv.qconfig = high_precision_qconfig\n",
    "        \n",
    "        # 为量化和反量化层设置配置\n",
    "        self.quant.qconfig = high_precision_qconfig\n",
    "        self.dequant.qconfig = high_precision_qconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3313739-b73a-4863-a818-5c9c7a5f5375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralDecomp(nn.Module):\n",
    "    \"\"\"支持多通道高光谱输入的频域分解\"\"\"\n",
    "    def __init__(self, spatial_radius=7, texture_contrast=0.8):\n",
    "        super().__init__()\n",
    "        self.spatial_radius = spatial_radius\n",
    "        self.texture_contrast = texture_contrast\n",
    "        \n",
    "        # 多通道高斯模糊\n",
    "        self.gaussian_blur = nn.Sequential(\n",
    "            nn.ReflectionPad2d(spatial_radius),\n",
    "            nn.Conv2d(1, 1, kernel_size=2*spatial_radius+1, bias=False)\n",
    "        )\n",
    "        self._init_gaussian_weights()\n",
    "        \n",
    "    def _init_gaussian_weights(self):\n",
    "        \"\"\"初始化适用于任意通道数的高斯核\"\"\"\n",
    "        sigma = self.spatial_radius/3\n",
    "        x = torch.arange(-self.spatial_radius, self.spatial_radius+1)\n",
    "        kernel = torch.exp(-x.pow(2)/(2*sigma**2))\n",
    "        kernel = kernel.view(1,1,-1) * kernel.view(1,1,-1,1)\n",
    "        self.gaussian_blur[1].weight.data = kernel / kernel.sum()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        输入: (B, C, H, W) 张量\n",
    "        输出: (low_freq, high_freq) 元组\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        # 多通道处理\n",
    "        x_flat = x.view(B*C, 1, H, W)  # 展平为(B*C, 1, H, W)\n",
    "        \n",
    "        # 低频分量\n",
    "        low = self.gaussian_blur(x_flat)\n",
    "        low = low.view(B, C, H, W)  # 恢复原始形状\n",
    "        \n",
    "        # 高频分量\n",
    "        high = (x - low) * self.texture_contrast\n",
    "        \n",
    "        return low, high\n",
    "        \n",
    "class MambaHSI_NEW(nn.Module):\n",
    "    def __init__(self,in_channels=128,hidden_dim=64,num_classes=10,use_residual=True,mamba_type='both',token_num=4,group_num=4,use_att=True):\n",
    "        super(MambaHSI_NEW, self).__init__()\n",
    "        self.mamba_type = mamba_type\n",
    "\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "        \n",
    "        self.patch_embedding = nn.Sequential(nn.Conv2d(in_channels=in_channels,out_channels=hidden_dim,kernel_size=1,stride=1,padding=0),\n",
    "                                             nn.GroupNorm(group_num,hidden_dim),\n",
    "                                             nn.SiLU())\n",
    "        \n",
    "        self.high_channel_128_32 = nn.Sequential(nn.Conv2d(in_channels=hidden_dim,out_channels=32,kernel_size=1,stride=1,padding=0),\n",
    "                                             nn.GroupNorm(group_num,32),\n",
    "                                             nn.SiLU())\n",
    "        \n",
    "        self.high_channel_160_32 = nn.Sequential(nn.Conv2d(in_channels=160,out_channels=32,kernel_size=1,stride=1,padding=0),\n",
    "                                             nn.GroupNorm(group_num,32),\n",
    "                                             nn.SiLU())\n",
    "        \n",
    "        self.low_channel_160_128 = Low_Model(in_channels=160,out_channels=128,kernel_size=1,stride=1,padding=0,index=False)\n",
    "        \n",
    "        self.low_channel_160_128_fin = nn.Sequential(nn.GroupNorm(group_num,128),nn.SiLU())\n",
    "        \n",
    "        self.low_channel_128_128 = Low_Model(in_channels=128,out_channels=128,kernel_size=1,stride=1,padding=0,index=True)\n",
    "        \n",
    "        self.low_channel_128_128_fin = nn.Sequential(nn.GroupNorm(group_num,128),nn.SiLU(),nn.AvgPool2d(kernel_size=2, stride=2, padding=0))\n",
    "                                            \n",
    "\n",
    "        self.decomp = SpectralDecomp(spatial_radius=7)\n",
    "        \n",
    "        if mamba_type == 'spa':\n",
    "            self.mamba = nn.Sequential(SpaMamba(hidden_dim,use_residual=use_residual,group_num=group_num),\n",
    "                                        nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "                                        SpaMamba(hidden_dim,use_residual=use_residual,group_num=group_num),\n",
    "                                        nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "                                        SpaMamba(hidden_dim,use_residual=use_residual,group_num=group_num),\n",
    "                                        )\n",
    "        elif mamba_type == 'spe':\n",
    "            self.mamba = nn.Sequential(SpeMamba(hidden_dim,token_num=token_num,use_residual=use_residual,group_num=group_num),\n",
    "                                        nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "                                        SpeMamba(hidden_dim,token_num=token_num,use_residual=use_residual,group_num=group_num),\n",
    "                                        nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "                                        SpeMamba(hidden_dim,token_num=token_num,use_residual=use_residual,group_num=group_num)\n",
    "                                        )\n",
    "\n",
    "        elif mamba_type=='both':\n",
    "            self.high_mamba = nn.Sequential(BothMamba(channels=32,token_num=token_num,use_residual=use_residual,group_num=group_num,use_att=use_att),\n",
    "                                       nn.AvgPool2d(kernel_size=2, stride=2, padding=0))\n",
    "        \n",
    "            \n",
    "            self.high_mamba_finally = BothMamba(channels=32,token_num=token_num,use_residual=use_residual,group_num=group_num,use_att=use_att)\n",
    "            self.low_mamba_finally = BothMamba(channels=hidden_dim,token_num=token_num,use_residual=use_residual,group_num=group_num,use_att=use_att)\n",
    "            \n",
    "        self.cls_head = nn.Sequential(nn.Conv2d(in_channels=hidden_dim+32, out_channels=64, kernel_size=1, stride=1, padding=0),\n",
    "                                      nn.GroupNorm(group_num,64),\n",
    "                                      nn.SiLU(),\n",
    "                                      nn.Conv2d(in_channels=64,out_channels=num_classes,kernel_size=1,stride=1,padding=0))\n",
    "\n",
    "    def forward(self,x):\n",
    "        #卷积层\n",
    "        x = self.patch_embedding(x)#128通道\n",
    "        #高低频拆解\n",
    "        #high,low = self.decomp(x)\n",
    "        low,high = self.decomp(x)\n",
    "        high = self.high_channel_128_32(high)\n",
    "        if args.exp_name == \"RESULT_INT8_Conv\":\n",
    "            high_mamba = self.high_mamba(high)\n",
    "        else:\n",
    "            high_mamba = self.high_mamba(high.half())\n",
    "        low_mamba = self.low_channel_128_128(low)\n",
    "        low_mamba = self.low_channel_128_128_fin(low_mamba)\n",
    "        \n",
    "        combined = torch.cat([low_mamba, high_mamba], dim=1)\n",
    "        #高低频拆解\n",
    "        #high,low = self.decomp(combined)\n",
    "        low,high = self.decomp(combined)\n",
    "        high = self.high_channel_160_32(high)\n",
    "        \n",
    "        low = self.low_channel_160_128(low)\n",
    "        low = self.low_channel_160_128_fin(low)\n",
    "        \n",
    "        if args.exp_name == \"RESULT_INT8_Conv\":\n",
    "            high_mamba = self.high_mamba(high)\n",
    "        else:\n",
    "            high_mamba = self.high_mamba(high.half())\n",
    "        low_mamba = self.low_channel_128_128(low) \n",
    "        low_mamba = self.low_channel_128_128_fin(low_mamba)\n",
    "        \n",
    "        combined = torch.cat([low_mamba, high_mamba], dim=1)\n",
    "        #高低频拆解\n",
    "        #high,low = self.decomp(combined)\n",
    "        low,high = self.decomp(combined)\n",
    "        high = self.high_channel_160_32(high)\n",
    "            \n",
    "        low = self.low_channel_160_128(low)\n",
    "        low = self.low_channel_160_128_fin(low)\n",
    "        \n",
    "        high_mamba = self.high_mamba_finally(high)\n",
    "        low_mamba = self.low_mamba_finally(low) \n",
    "\n",
    "        combined = torch.cat([low_mamba, high_mamba], dim=1)\n",
    "        logits = self.cls_head(combined)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9077b085-1e1d-49c1-be7d-c8879a5e2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridOptimizer:\n",
    "    def __init__(self, model, base_lr=0.0003):\n",
    "        # 分离参数组\n",
    "        self.fp16_params = []\n",
    "        self.fp32_params = []\n",
    "        \n",
    "        # 自动识别参数类型\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.dtype == torch.float16:\n",
    "                self.fp16_params.append(param)\n",
    "                param.requires_grad_(True)  # 确保梯度计算\n",
    "            else:\n",
    "                self.fp32_params.append(param)\n",
    "        \n",
    "        # 仅初始化FP32优化器\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.fp32_params, \n",
    "            lr=base_lr,\n",
    "        )\n",
    "        \n",
    "        # FP16手动优化参数\n",
    "        self.fp16_lr = base_lr * 10  # 更高学习率\n",
    "        self.grad_clip = 1.0\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"执行参数更新\"\"\"\n",
    "        # 先更新FP32参数\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # 手动更新FP16参数\n",
    "        with torch.no_grad():\n",
    "            for param in self.fp16_params:\n",
    "                if param.grad is not None:\n",
    "                    # 梯度裁剪\n",
    "                    grad = torch.clamp(param.grad, -self.grad_clip, self.grad_clip)\n",
    "                    # 参数更新 (SGD示例)\n",
    "                    param.data.sub_(self.fp16_lr * grad)\n",
    "                    \n",
    "                    # 可选：Adam风格更新\n",
    "                    # self._adam_update(param, grad)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"统一清空梯度\"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        for param in self.fp16_params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.detach_()\n",
    "                param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3dab019-f8a2-408c-b5e0-128f3752bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_model_high_mamba_float16(model):\n",
    "# 获取conv1d层权重\n",
    "    spa_weight_conv1d_16 = model.high_mamba[0].spa_mamba.mamba.conv1d.weight.data.to(torch.float16)\n",
    "    spe_weight_conv1d_16 = model.high_mamba[0].spe_mamba.mamba.conv1d.weight.data.to(torch.float16)\n",
    "    # 替换权重（保持相同设备）\n",
    "    model.high_mamba[0].spa_mamba.mamba.conv1d.weight = torch.nn.Parameter(spa_weight_conv1d_16.to(model.high_mamba[0].spa_mamba.mamba.conv1d.weight.device))\n",
    "    model.high_mamba[0].spe_mamba.mamba.conv1d.weight = torch.nn.Parameter(spe_weight_conv1d_16.to(model.high_mamba[0].spe_mamba.mamba.conv1d.weight.device))\n",
    "    # 获取conv1d层偏置项\n",
    "    spa_bias_conv1d_16 = model.high_mamba[0].spa_mamba.mamba.conv1d.bias.data.to(torch.float16)\n",
    "    spe_bias_conv1d_16 = model.high_mamba[0].spe_mamba.mamba.conv1d.bias.data.to(torch.float16)\n",
    "    # 替换偏置项（保持相同设备）\n",
    "    model.high_mamba[0].spa_mamba.mamba.conv1d.bias = torch.nn.Parameter(spa_bias_conv1d_16.to(model.high_mamba[0].spa_mamba.mamba.conv1d.bias.device))\n",
    "    model.high_mamba[0].spe_mamba.mamba.conv1d.bias = torch.nn.Parameter(spe_bias_conv1d_16.to(model.high_mamba[0].spe_mamba.mamba.conv1d.bias.device))\n",
    "\n",
    "    # 获取in_proj权重\n",
    "    spa_weight_in_proj_16 = model.high_mamba[0].spa_mamba.mamba.in_proj.weight.data.to(torch.float16)\n",
    "    spe_weight_in_proj_16 = model.high_mamba[0].spe_mamba.mamba.in_proj.weight.data.to(torch.float16)\n",
    "    # 替换权重（保持相同设备）\n",
    "    model.high_mamba[0].spa_mamba.mamba.in_proj.weight = torch.nn.Parameter(spa_weight_in_proj_16.to(model.high_mamba[0].spa_mamba.mamba.in_proj.weight.device))\n",
    "    model.high_mamba[0].spe_mamba.mamba.in_proj.weight = torch.nn.Parameter(spe_weight_in_proj_16.to(model.high_mamba[0].spe_mamba.mamba.in_proj.weight.device))\n",
    "    \n",
    "    # 获取x_proj权重\n",
    "    spa_weight_x_proj_16 = model.high_mamba[0].spa_mamba.mamba.x_proj.weight.data.to(torch.float16)\n",
    "    spe_weight_x_proj_16 = model.high_mamba[0].spe_mamba.mamba.x_proj.weight.data.to(torch.float16)\n",
    "    # 替换权重（保持相同设备）\n",
    "    model.high_mamba[0].spa_mamba.mamba.x_proj.weight = torch.nn.Parameter(spa_weight_x_proj_16.to(model.high_mamba[0].spa_mamba.mamba.x_proj.weight.device))\n",
    "    model.high_mamba[0].spe_mamba.mamba.x_proj.weight = torch.nn.Parameter(spe_weight_x_proj_16.to(model.high_mamba[0].spe_mamba.mamba.x_proj.weight.device))\n",
    "    \n",
    "    # 获取dt_proj权重\n",
    "    spa_weight_dt_proj_16 = model.high_mamba[0].spa_mamba.mamba.dt_proj.weight.data.to(torch.float16)\n",
    "    spe_weight_dt_proj_16 = model.high_mamba[0].spe_mamba.mamba.dt_proj.weight.data.to(torch.float16)\n",
    "    # 替换权重（保持相同设备）\n",
    "    model.high_mamba[0].spa_mamba.mamba.dt_proj.weight = torch.nn.Parameter(spa_weight_dt_proj_16.to(model.high_mamba[0].spa_mamba.mamba.dt_proj.weight.device))\n",
    "    model.high_mamba[0].spe_mamba.mamba.dt_proj.weight = torch.nn.Parameter(spe_weight_dt_proj_16.to(model.high_mamba[0].spe_mamba.mamba.dt_proj.weight.device))\n",
    "    \n",
    "    # 获取out_proj权重\n",
    "    spa_weight_out_proj_16 = model.high_mamba[0].spa_mamba.mamba.out_proj.weight.data.to(torch.float16)\n",
    "    spe_weight_out_proj_16 = model.high_mamba[0].spe_mamba.mamba.out_proj.weight.data.to(torch.float16)\n",
    "    # 替换权重（保持相同设备）\n",
    "    model.high_mamba[0].spa_mamba.mamba.out_proj.weight = torch.nn.Parameter(spa_weight_out_proj_16.to(model.high_mamba[0].spa_mamba.mamba.out_proj.weight.device))\n",
    "    model.high_mamba[0].spe_mamba.mamba.out_proj.weight = torch.nn.Parameter(spe_weight_out_proj_16.to(model.high_mamba[0].spe_mamba.mamba.out_proj.weight.device))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42e32e47-6044-42e0-a9d1-d010e42dfa90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 250519 10:28:19 3690967061:13] ./RESULT_INT8_Conv/MambaHSI/HongHu\n",
      "[I 250519 10:28:26 3690967061:61] {'net_name': 'MambaHSI', 'dataset_index': 2, 'num_list': [30, 10], 'lr': 0.0003, 'seed_list': [0]}\n",
      "[I 250519 10:28:26 3690967061:62] MambaHSI_NEW(\n",
      "      (quant): QuantStub()\n",
      "      (dequant): DeQuantStub()\n",
      "      (patch_embedding): Sequential(\n",
      "        (0): Conv2d(270, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
      "        (2): SiLU()\n",
      "      )\n",
      "      (high_channel_128_32): Sequential(\n",
      "        (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "        (2): SiLU()\n",
      "      )\n",
      "      (high_channel_160_32): Sequential(\n",
      "        (0): Conv2d(160, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "        (2): SiLU()\n",
      "      )\n",
      "      (low_channel_160_128): Low_Model(\n",
      "        (quant): QuantStub(\n",
      "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
      "        )\n",
      "        (conv): Conv2d(\n",
      "          160, 128, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
      "        )\n",
      "        (dequant): DeQuantStub()\n",
      "      )\n",
      "      (low_channel_160_128_fin): Sequential(\n",
      "        (0): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "      )\n",
      "      (low_channel_128_128): Low_Model(\n",
      "        (quant): QuantStub(\n",
      "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
      "        )\n",
      "        (conv): Conv2d(\n",
      "          128, 128, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
      "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
      "        )\n",
      "        (dequant): DeQuantStub()\n",
      "      )\n",
      "      (low_channel_128_128_fin): Sequential(\n",
      "        (0): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (decomp): SpectralDecomp(\n",
      "        (gaussian_blur): Sequential(\n",
      "          (0): ReflectionPad2d((7, 7, 7, 7))\n",
      "          (1): Conv2d(1, 1, kernel_size=(15, 15), stride=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (high_mamba): Sequential(\n",
      "        (0): BothMamba(\n",
      "          (softmax): Softmax(dim=0)\n",
      "          (spa_mamba): SpaMamba(\n",
      "            (mamba): Mamba(\n",
      "              (in_proj): Linear(in_features=32, out_features=128, bias=False)\n",
      "              (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)\n",
      "              (act): SiLU()\n",
      "              (x_proj): Linear(in_features=64, out_features=34, bias=False)\n",
      "              (dt_proj): Linear(in_features=2, out_features=64, bias=True)\n",
      "              (out_proj): Linear(in_features=64, out_features=32, bias=False)\n",
      "            )\n",
      "            (proj): Sequential(\n",
      "              (0): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "            )\n",
      "          )\n",
      "          (spe_mamba): SpeMamba(\n",
      "            (mamba): Mamba(\n",
      "              (in_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "              (conv1d): Conv1d(16, 16, kernel_size=(4,), stride=(1,), padding=(3,), groups=16)\n",
      "              (act): SiLU()\n",
      "              (x_proj): Linear(in_features=16, out_features=33, bias=False)\n",
      "              (dt_proj): Linear(in_features=1, out_features=16, bias=True)\n",
      "              (out_proj): Linear(in_features=16, out_features=8, bias=False)\n",
      "            )\n",
      "            (proj): Sequential(\n",
      "              (0): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              (1): SiLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (high_mamba_finally): BothMamba(\n",
      "        (softmax): Softmax(dim=0)\n",
      "        (spa_mamba): SpaMamba(\n",
      "          (mamba): Mamba(\n",
      "            (in_proj): Linear(in_features=32, out_features=128, bias=False)\n",
      "            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)\n",
      "            (act): SiLU()\n",
      "            (x_proj): Linear(in_features=64, out_features=34, bias=False)\n",
      "            (dt_proj): Linear(in_features=2, out_features=64, bias=True)\n",
      "            (out_proj): Linear(in_features=64, out_features=32, bias=False)\n",
      "          )\n",
      "          (proj): Sequential(\n",
      "            (0): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "            (1): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (spe_mamba): SpeMamba(\n",
      "          (mamba): Mamba(\n",
      "            (in_proj): Linear(in_features=8, out_features=32, bias=False)\n",
      "            (conv1d): Conv1d(16, 16, kernel_size=(4,), stride=(1,), padding=(3,), groups=16)\n",
      "            (act): SiLU()\n",
      "            (x_proj): Linear(in_features=16, out_features=33, bias=False)\n",
      "            (dt_proj): Linear(in_features=1, out_features=16, bias=True)\n",
      "            (out_proj): Linear(in_features=16, out_features=8, bias=False)\n",
      "          )\n",
      "          (proj): Sequential(\n",
      "            (0): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "            (1): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (low_mamba_finally): BothMamba(\n",
      "        (softmax): Softmax(dim=0)\n",
      "        (spa_mamba): SpaMamba(\n",
      "          (mamba): Mamba(\n",
      "            (in_proj): Linear(in_features=128, out_features=512, bias=False)\n",
      "            (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
      "            (act): SiLU()\n",
      "            (x_proj): Linear(in_features=256, out_features=40, bias=False)\n",
      "            (dt_proj): Linear(in_features=8, out_features=256, bias=True)\n",
      "            (out_proj): Linear(in_features=256, out_features=128, bias=False)\n",
      "          )\n",
      "          (proj): Sequential(\n",
      "            (0): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
      "            (1): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (spe_mamba): SpeMamba(\n",
      "          (mamba): Mamba(\n",
      "            (in_proj): Linear(in_features=32, out_features=128, bias=False)\n",
      "            (conv1d): Conv1d(64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)\n",
      "            (act): SiLU()\n",
      "            (x_proj): Linear(in_features=64, out_features=34, bias=False)\n",
      "            (dt_proj): Linear(in_features=2, out_features=64, bias=True)\n",
      "            (out_proj): Linear(in_features=64, out_features=32, bias=False)\n",
      "          )\n",
      "          (proj): Sequential(\n",
      "            (0): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
      "            (1): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (cls_head): Sequential(\n",
      "        (0): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
      "        (2): SiLU()\n",
      "        (3): Conv2d(64, 22, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "[I 250519 10:28:26 3690967061:82] Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: None\n",
      "        lr: 0.0003\n",
      "        maximize: False\n",
      "        weight_decay: 0\n",
      "    )\n",
      "[I 250519 10:28:27 3690967061:90] para:243.68 K\n",
      "    ,flops:109.17 GFLOPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  243.68 K\n",
      "fwd MACs:                                                               53.82 GMACs\n",
      "fwd FLOPs:                                                              109.17 GFLOPS\n",
      "fwd+bwd MACs:                                                           161.47 GMACs\n",
      "fwd+bwd FLOPs:                                                          327.52 GFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "MambaHSI_NEW(\n",
      "  243.68 K = 100% Params, 53.82 GMACs = 100% MACs, 109.17 GFLOPS = 100% FLOPs\n",
      "  (quant): QuantStub(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  (dequant): DeQuantStub(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  (patch_embedding): Sequential(\n",
      "    34.94 K = 14.34% Params, 15.43 GMACs = 28.67% MACs, 31.26 GFLOPS = 28.64% FLOPs\n",
      "    (0): Conv2d(34.69 K = 14.24% Params, 15.43 GMACs = 28.67% MACs, 30.92 GFLOPS = 28.32% FLOPs, 270, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): GroupNorm(256 = 0.11% Params, 0 MACs = 0% MACs, 285.76 MFLOPS = 0.26% FLOPs, 4, 128, eps=1e-05, affine=True)\n",
      "    (2): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 57.15 MFLOPS = 0.05% FLOPs)\n",
      "  )\n",
      "  (high_channel_128_32): Sequential(\n",
      "    4.19 K = 1.72% Params, 1.83 GMACs = 3.4% MACs, 3.76 GFLOPS = 3.44% FLOPs\n",
      "    (0): Conv2d(4.13 K = 1.69% Params, 1.83 GMACs = 3.4% MACs, 3.67 GFLOPS = 3.36% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): GroupNorm(64 = 0.03% Params, 0 MACs = 0% MACs, 71.44 MFLOPS = 0.07% FLOPs, 4, 32, eps=1e-05, affine=True)\n",
      "    (2): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 14.29 MFLOPS = 0.01% FLOPs)\n",
      "  )\n",
      "  (high_channel_160_32): Sequential(\n",
      "    5.22 K = 2.14% Params, 712.29 MMACs = 1.32% MACs, 1.46 GFLOPS = 1.33% FLOPs\n",
      "    (0): Conv2d(5.15 K = 2.11% Params, 712.29 MMACs = 1.32% MACs, 1.43 GFLOPS = 1.31% FLOPs, 160, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): GroupNorm(64 = 0.03% Params, 0 MACs = 0% MACs, 22.26 MFLOPS = 0.02% FLOPs, 4, 32, eps=1e-05, affine=True)\n",
      "    (2): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 4.45 MFLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (low_channel_160_128): Low_Model(\n",
      "    20.61 K = 8.46% Params, 2.85 GMACs = 5.29% MACs, 5.72 GFLOPS = 5.24% FLOPs\n",
      "    (quant): QuantStub(\n",
      "      0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs\n",
      "      (activation_post_process): MovingAverageMinMaxObserver(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, min_val=-0.6774353981018066, max_val=5.074414253234863)\n",
      "    )\n",
      "    (conv): Conv2d(\n",
      "      20.61 K = 8.46% Params, 2.85 GMACs = 5.29% MACs, 5.72 GFLOPS = 5.24% FLOPs, 160, 128, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (weight_fake_quant): MinMaxObserver(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, min_val=-0.07905228435993195, max_val=0.07904726266860962)\n",
      "      (activation_post_process): MovingAverageMinMaxObserver(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, min_val=-1.2829294204711914, max_val=0.9451835751533508)\n",
      "    )\n",
      "    (dequant): DeQuantStub(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (low_channel_160_128_fin): Sequential(\n",
      "    256 = 0.11% Params, 0 MACs = 0% MACs, 106.84 MFLOPS = 0.1% FLOPs\n",
      "    (0): GroupNorm(256 = 0.11% Params, 0 MACs = 0% MACs, 89.04 MFLOPS = 0.08% FLOPs, 4, 128, eps=1e-05, affine=True)\n",
      "    (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 17.81 MFLOPS = 0.02% FLOPs)\n",
      "  )\n",
      "  (low_channel_128_128): Low_Model(\n",
      "    16.51 K = 6.78% Params, 9.14 GMACs = 16.98% MACs, 18.35 GFLOPS = 16.81% FLOPs\n",
      "    (quant): QuantStub(\n",
      "      0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs\n",
      "      (activation_post_process): MovingAverageMinMaxObserver(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, min_val=-0.2782784402370453, max_val=1.642090916633606)\n",
      "    )\n",
      "    (conv): Conv2d(\n",
      "      16.51 K = 6.78% Params, 9.14 GMACs = 16.98% MACs, 18.35 GFLOPS = 16.81% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (weight_fake_quant): MinMaxObserver(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, min_val=-0.08837797492742538, max_val=0.08838692307472229)\n",
      "      (activation_post_process): MovingAverageMinMaxObserver(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, min_val=-0.9562490582466125, max_val=0.8514744639396667)\n",
      "    )\n",
      "    (dequant): DeQuantStub(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (low_channel_128_128_fin): Sequential(\n",
      "    256 = 0.11% Params, 0 MACs = 0% MACs, 499.87 MFLOPS = 0.46% FLOPs\n",
      "    (0): GroupNorm(256 = 0.11% Params, 0 MACs = 0% MACs, 357.05 MFLOPS = 0.33% FLOPs, 4, 128, eps=1e-05, affine=True)\n",
      "    (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 71.41 MFLOPS = 0.07% FLOPs)\n",
      "    (2): AvgPool2d(0 = 0% Params, 0 MACs = 0% MACs, 71.41 MFLOPS = 0.07% FLOPs, kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (decomp): SpectralDecomp(\n",
      "    225 = 0.09% Params, 17.87 GMACs = 33.2% MACs, 35.74 GFLOPS = 32.73% FLOPs\n",
      "    (gaussian_blur): Sequential(\n",
      "      225 = 0.09% Params, 17.87 GMACs = 33.2% MACs, 35.74 GFLOPS = 32.73% FLOPs\n",
      "      (0): ReflectionPad2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, (7, 7, 7, 7))\n",
      "      (1): Conv2d(225 = 0.09% Params, 17.87 GMACs = 33.2% MACs, 35.74 GFLOPS = 32.73% FLOPs, 1, 1, kernel_size=(15, 15), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (high_mamba): Sequential(\n",
      "    11.35 K = 4.66% Params, 3.82 GMACs = 7.1% MACs, 7.87 GFLOPS = 7.21% FLOPs\n",
      "    (0): BothMamba(\n",
      "      11.35 K = 4.66% Params, 3.82 GMACs = 7.1% MACs, 7.86 GFLOPS = 7.2% FLOPs\n",
      "      (softmax): Softmax(0 = 0% Params, 0 MACs = 0% MACs, 4 FLOPS = 0% FLOPs, dim=0)\n",
      "      (spa_mamba): SpaMamba(\n",
      "        9.98 K = 4.1% Params, 2.36 GMACs = 4.38% MACs, 4.82 GFLOPS = 4.42% FLOPs\n",
      "        (mamba): Mamba(\n",
      "          9.92 K = 4.07% Params, 2.36 GMACs = 4.38% MACs, 4.71 GFLOPS = 4.32% FLOPs\n",
      "          (in_proj): Linear(4.1 K = 1.68% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=32, out_features=128, bias=False)\n",
      "          (conv1d): Conv1d(320 = 0.13% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)\n",
      "          (act): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          (x_proj): Linear(2.18 K = 0.89% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=34, bias=False)\n",
      "          (dt_proj): Linear(192 = 0.08% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=2, out_features=64, bias=True)\n",
      "          (out_proj): Linear(2.05 K = 0.84% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=32, bias=False)\n",
      "        )\n",
      "        (proj): Sequential(\n",
      "          64 = 0.03% Params, 0 MACs = 0% MACs, 107.11 MFLOPS = 0.1% FLOPs\n",
      "          (0): GroupNorm(64 = 0.03% Params, 0 MACs = 0% MACs, 89.26 MFLOPS = 0.08% FLOPs, 4, 32, eps=1e-05, affine=True)\n",
      "          (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 17.85 MFLOPS = 0.02% FLOPs)\n",
      "        )\n",
      "      )\n",
      "      (spe_mamba): SpeMamba(\n",
      "        1.36 K = 0.56% Params, 1.46 GMACs = 2.72% MACs, 3.03 GFLOPS = 2.78% FLOPs\n",
      "        (mamba): Mamba(\n",
      "          1.3 K = 0.53% Params, 1.46 GMACs = 2.72% MACs, 2.93 GFLOPS = 2.68% FLOPs\n",
      "          (in_proj): Linear(256 = 0.11% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=8, out_features=32, bias=False)\n",
      "          (conv1d): Conv1d(80 = 0.03% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 16, 16, kernel_size=(4,), stride=(1,), padding=(3,), groups=16)\n",
      "          (act): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          (x_proj): Linear(528 = 0.22% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=16, out_features=33, bias=False)\n",
      "          (dt_proj): Linear(32 = 0.01% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=1, out_features=16, bias=True)\n",
      "          (out_proj): Linear(128 = 0.05% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=16, out_features=8, bias=False)\n",
      "        )\n",
      "        (proj): Sequential(\n",
      "          64 = 0.03% Params, 0 MACs = 0% MACs, 107.11 MFLOPS = 0.1% FLOPs\n",
      "          (0): GroupNorm(64 = 0.03% Params, 0 MACs = 0% MACs, 89.26 MFLOPS = 0.08% FLOPs, 4, 32, eps=1e-05, affine=True)\n",
      "          (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 17.85 MFLOPS = 0.02% FLOPs)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): AvgPool2d(0 = 0% Params, 0 MACs = 0% MACs, 17.85 MFLOPS = 0.02% FLOPs, kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (high_mamba_finally): BothMamba(\n",
      "    11.35 K = 4.66% Params, 189.9 MMACs = 0.35% MACs, 390.44 MFLOPS = 0.36% FLOPs\n",
      "    (softmax): Softmax(0 = 0% Params, 0 MACs = 0% MACs, 2 FLOPS = 0% FLOPs, dim=0)\n",
      "    (spa_mamba): SpaMamba(\n",
      "      9.98 K = 4.1% Params, 117.13 MMACs = 0.22% MACs, 239.59 MFLOPS = 0.22% FLOPs\n",
      "      (mamba): Mamba(\n",
      "        9.92 K = 4.07% Params, 117.13 MMACs = 0.22% MACs, 234.26 MFLOPS = 0.21% FLOPs\n",
      "        (in_proj): Linear(4.1 K = 1.68% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=32, out_features=128, bias=False)\n",
      "        (conv1d): Conv1d(320 = 0.13% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)\n",
      "        (act): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        (x_proj): Linear(2.18 K = 0.89% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=34, bias=False)\n",
      "        (dt_proj): Linear(192 = 0.08% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=2, out_features=64, bias=True)\n",
      "        (out_proj): Linear(2.05 K = 0.84% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "      (proj): Sequential(\n",
      "        64 = 0.03% Params, 0 MACs = 0% MACs, 5.32 MFLOPS = 0% FLOPs\n",
      "        (0): GroupNorm(64 = 0.03% Params, 0 MACs = 0% MACs, 4.44 MFLOPS = 0% FLOPs, 4, 32, eps=1e-05, affine=True)\n",
      "        (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 887.36 KFLOPS = 0% FLOPs)\n",
      "      )\n",
      "    )\n",
      "    (spe_mamba): SpeMamba(\n",
      "      1.36 K = 0.56% Params, 72.76 MMACs = 0.14% MACs, 150.85 MFLOPS = 0.14% FLOPs\n",
      "      (mamba): Mamba(\n",
      "        1.3 K = 0.53% Params, 72.76 MMACs = 0.14% MACs, 145.53 MFLOPS = 0.13% FLOPs\n",
      "        (in_proj): Linear(256 = 0.11% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=8, out_features=32, bias=False)\n",
      "        (conv1d): Conv1d(80 = 0.03% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 16, 16, kernel_size=(4,), stride=(1,), padding=(3,), groups=16)\n",
      "        (act): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        (x_proj): Linear(528 = 0.22% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=16, out_features=33, bias=False)\n",
      "        (dt_proj): Linear(32 = 0.01% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=1, out_features=16, bias=True)\n",
      "        (out_proj): Linear(128 = 0.05% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=16, out_features=8, bias=False)\n",
      "      )\n",
      "      (proj): Sequential(\n",
      "        64 = 0.03% Params, 0 MACs = 0% MACs, 5.32 MFLOPS = 0% FLOPs\n",
      "        (0): GroupNorm(64 = 0.03% Params, 0 MACs = 0% MACs, 4.44 MFLOPS = 0% FLOPs, 4, 32, eps=1e-05, affine=True)\n",
      "        (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 887.36 KFLOPS = 0% FLOPs)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (low_mamba_finally): BothMamba(\n",
      "    126.91 K = 52.08% Params, 1.66 GMACs = 3.09% MACs, 3.36 GFLOPS = 3.08% FLOPs\n",
      "    (softmax): Softmax(0 = 0% Params, 0 MACs = 0% MACs, 2 FLOPS = 0% FLOPs, dim=0)\n",
      "    (spa_mamba): SpaMamba(\n",
      "      116.74 K = 47.91% Params, 1.19 GMACs = 2.22% MACs, 2.41 GFLOPS = 2.2% FLOPs\n",
      "      (mamba): Mamba(\n",
      "        116.48 K = 47.8% Params, 1.19 GMACs = 2.22% MACs, 2.39 GFLOPS = 2.18% FLOPs\n",
      "        (in_proj): Linear(65.54 K = 26.89% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=128, out_features=512, bias=False)\n",
      "        (conv1d): Conv1d(1.28 K = 0.53% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
      "        (act): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        (x_proj): Linear(10.24 K = 4.2% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=256, out_features=40, bias=False)\n",
      "        (dt_proj): Linear(2.3 K = 0.95% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=8, out_features=256, bias=True)\n",
      "        (out_proj): Linear(32.77 K = 13.45% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=256, out_features=128, bias=False)\n",
      "      )\n",
      "      (proj): Sequential(\n",
      "        256 = 0.11% Params, 0 MACs = 0% MACs, 21.3 MFLOPS = 0.02% FLOPs\n",
      "        (0): GroupNorm(256 = 0.11% Params, 0 MACs = 0% MACs, 17.75 MFLOPS = 0.02% FLOPs, 4, 128, eps=1e-05, affine=True)\n",
      "        (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 3.55 MFLOPS = 0% FLOPs)\n",
      "      )\n",
      "    )\n",
      "    (spe_mamba): SpeMamba(\n",
      "      10.18 K = 4.18% Params, 468.53 MMACs = 0.87% MACs, 958.35 MFLOPS = 0.88% FLOPs\n",
      "      (mamba): Mamba(\n",
      "        9.92 K = 4.07% Params, 468.53 MMACs = 0.87% MACs, 937.05 MFLOPS = 0.86% FLOPs\n",
      "        (in_proj): Linear(4.1 K = 1.68% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=32, out_features=128, bias=False)\n",
      "        (conv1d): Conv1d(320 = 0.13% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)\n",
      "        (act): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        (x_proj): Linear(2.18 K = 0.89% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=34, bias=False)\n",
      "        (dt_proj): Linear(192 = 0.08% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=2, out_features=64, bias=True)\n",
      "        (out_proj): Linear(2.05 K = 0.84% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "      (proj): Sequential(\n",
      "        256 = 0.11% Params, 0 MACs = 0% MACs, 21.3 MFLOPS = 0.02% FLOPs\n",
      "        (0): GroupNorm(256 = 0.11% Params, 0 MACs = 0% MACs, 17.75 MFLOPS = 0.02% FLOPs, 4, 128, eps=1e-05, affine=True)\n",
      "        (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 3.55 MFLOPS = 0% FLOPs)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (cls_head): Sequential(\n",
      "    11.86 K = 4.87% Params, 323 MMACs = 0.6% MACs, 659.03 MFLOPS = 0.6% FLOPs\n",
      "    (0): Conv2d(10.3 K = 4.23% Params, 283.96 MMACs = 0.53% MACs, 569.69 MFLOPS = 0.52% FLOPs, 160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): GroupNorm(128 = 0.05% Params, 0 MACs = 0% MACs, 8.87 MFLOPS = 0.01% FLOPs, 4, 64, eps=1e-05, affine=True)\n",
      "    (2): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 1.77 MFLOPS = 0% FLOPs)\n",
      "    (3): Conv2d(1.43 K = 0.59% Params, 39.04 MMACs = 0.07% MACs, 78.7 MFLOPS = 0.07% FLOPs, 64, 22, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 250519 10:28:27 3690967061:135] Iter:0|loss:3.205061912536621\n",
      "[I 250519 10:28:28 3690967061:178] Evaluate 0|OA:0.05909090909090909|MACC:0.059090909090909104|Kappa:0.014285714285714282|MIOU:0.009359405644235364|IOU:[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.0752\n",
      "     0.     0.     0.     0.     0.     0.0196 0.     0.     0.0833 0.\n",
      "     0.0278 0.    ]|ACC:[0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.1 0.  0.\n",
      "     0.1 0.  0.1 0. ]\n",
      "[I 250519 10:28:29 3690967061:135] Iter:1|loss:3.060872793197632\n",
      "[I 250519 10:28:29 3690967061:178] Evaluate 1|OA:0.10454545454545454|MACC:0.10454545454545455|Kappa:0.06190476190476189|MIOU:0.017921705202654892|IOU:[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.0862\n",
      "     0.0769 0.     0.     0.     0.     0.1311 0.     0.     0.     0.\n",
      "     0.1    0.    ]|ACC:[0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.1 0.  0.  0.  0.  0.8 0.  0.\n",
      "     0.  0.  0.4 0. ]\n",
      "[I 250519 10:28:30 3690967061:135] Iter:2|loss:2.968271493911743\n",
      "[I 250519 10:28:31 3690967061:178] Evaluate 2|OA:0.11818181818181818|MACC:0.11818181818181818|Kappa:0.07619047619047618|MIOU:0.02435086338707284|IOU:[0.     0.     0.     0.     0.     0.0526 0.     0.     0.     0.1538\n",
      "     0.0667 0.0588 0.     0.     0.     0.1449 0.     0.     0.     0.\n",
      "     0.0588 0.    ]|ACC:[0.  0.  0.  0.  0.  0.2 0.  0.  0.  1.  0.1 0.1 0.  0.  0.  1.  0.  0.\n",
      "     0.  0.  0.2 0. ]\n",
      "[I 250519 10:28:31 3690967061:135] Iter:3|loss:2.9037561416625977\n",
      "[I 250519 10:28:32 3690967061:178] Evaluate 3|OA:0.15|MACC:0.15000000000000002|Kappa:0.10952380952380951|MIOU:0.037982765702586865|IOU:[0.     0.     0.     0.     0.     0.1311 0.     0.     0.     0.2857\n",
      "     0.0667 0.     0.0833 0.     0.0556 0.1299 0.     0.     0.     0.\n",
      "     0.0833 0.    ]|ACC:[0.  0.  0.  0.  0.  0.8 0.  0.  0.  1.  0.1 0.  0.1 0.  0.1 1.  0.  0.\n",
      "     0.  0.  0.2 0. ]\n",
      "[I 250519 10:28:33 3690967061:135] Iter:4|loss:2.8355565071105957\n",
      "[I 250519 10:28:34 3690967061:178] Evaluate 4|OA:0.15|MACC:0.15000000000000002|Kappa:0.10952380952380951|MIOU:0.03555395807557505|IOU:[0.     0.     0.     0.     0.     0.1509 0.     0.     0.     0.2564\n",
      "     0.1    0.     0.     0.     0.0476 0.122  0.     0.     0.     0.\n",
      "     0.1053 0.    ]|ACC:[0.  0.  0.  0.  0.  0.8 0.  0.  0.  1.  0.2 0.  0.  0.  0.1 1.  0.  0.\n",
      "     0.  0.  0.2 0. ]\n",
      "[I 250519 10:28:34 3690967061:135] Iter:5|loss:2.763432502746582\n",
      "[I 250519 10:28:35 3690967061:178] Evaluate 5|OA:0.1590909090909091|MACC:0.15909090909090912|Kappa:0.11904761904761904|MIOU:0.04449138889112221|IOU:[0.     0.     0.     0.     0.     0.1739 0.     0.     0.     0.303\n",
      "     0.1071 0.     0.     0.     0.05   0.1205 0.0909 0.     0.     0.\n",
      "     0.1333 0.    ]|ACC:[0.  0.  0.  0.  0.  0.8 0.  0.  0.  1.  0.3 0.  0.  0.  0.1 1.  0.1 0.\n",
      "     0.  0.  0.2 0. ]\n",
      "[I 250519 10:28:36 3690967061:135] Iter:6|loss:2.7000248432159424\n",
      "[I 250519 10:28:36 3690967061:178] Evaluate 6|OA:0.20909090909090908|MACC:0.2090909090909091|Kappa:0.17142857142857143|MIOU:0.07718446302205893|IOU:[0.1667 0.     0.     0.     0.     0.25   0.     0.     0.     0.4167\n",
      "     0.125  0.0714 0.     0.     0.0667 0.1471 0.2174 0.     0.0833 0.1538\n",
      "     0.     0.    ]|ACC:[0.2 0.  0.  0.  0.  0.8 0.  0.  0.  1.  0.5 0.1 0.  0.  0.1 1.  0.5 0.\n",
      "     0.2 0.2 0.  0. ]\n",
      "[I 250519 10:28:37 3690967061:135] Iter:7|loss:2.6470959186553955\n",
      "[I 250519 10:28:38 3690967061:178] Evaluate 7|OA:0.20454545454545456|MACC:0.20454545454545456|Kappa:0.16666666666666669|MIOU:0.07958253231362475|IOU:[0.0769 0.     0.     0.     0.     0.3333 0.     0.     0.     0.5\n",
      "     0.1224 0.0833 0.     0.     0.0588 0.0714 0.2353 0.     0.1923 0.0769\n",
      "     0.     0.    ]|ACC:[0.2 0.  0.  0.  0.  0.8 0.  0.  0.  1.  0.6 0.1 0.  0.  0.1 0.3 0.8 0.\n",
      "     0.5 0.1 0.  0. ]\n",
      "[I 250519 10:28:39 3690967061:135] Iter:8|loss:2.602572441101074\n",
      "[I 250519 10:28:39 3690967061:178] Evaluate 8|OA:0.20909090909090908|MACC:0.2090909090909091|Kappa:0.17142857142857143|MIOU:0.08293149832623517|IOU:[0.1143 0.0667 0.     0.     0.     0.4211 0.     0.     0.     0.5263\n",
      "     0.1458 0.     0.     0.0833 0.0625 0.0714 0.1731 0.     0.16   0.\n",
      "     0.     0.    ]|ACC:[0.4 0.1 0.  0.  0.  0.8 0.  0.  0.  1.  0.7 0.  0.  0.1 0.1 0.1 0.9 0.\n",
      "     0.4 0.  0.  0. ]\n",
      "[I 250519 10:28:40 3690967061:135] Iter:9|loss:2.5552892684936523\n",
      "[I 250519 10:28:41 3690967061:178] Evaluate 9|OA:0.21818181818181817|MACC:0.21818181818181823|Kappa:0.18095238095238095|MIOU:0.09554972597999617|IOU:[0.1053 0.0556 0.     0.     0.     0.4444 0.     0.     0.2    0.5263\n",
      "     0.1176 0.     0.     0.0833 0.0714 0.0833 0.1875 0.     0.2273 0.\n",
      "     0.     0.    ]|ACC:[0.4 0.1 0.  0.  0.  0.8 0.  0.  0.2 1.  0.6 0.  0.  0.1 0.1 0.1 0.9 0.\n",
      "     0.5 0.  0.  0. ]\n",
      "[I 250519 10:28:41 3690967061:135] Iter:10|loss:2.5096893310546875\n",
      "[I 250519 10:28:42 3690967061:178] Evaluate 10|OA:0.2818181818181818|MACC:0.2818181818181818|Kappa:0.24761904761904757|MIOU:0.14611260928457664|IOU:[0.1282 0.0952 0.     0.     0.     0.4444 0.     0.     0.4    0.5\n",
      "     0.1404 0.1765 0.     0.0909 0.1667 0.4545 0.2647 0.     0.3529 0.\n",
      "     0.     0.    ]|ACC:[0.5 0.2 0.  0.  0.  0.8 0.  0.  0.4 0.9 0.8 0.3 0.  0.1 0.2 0.5 0.9 0.\n",
      "     0.6 0.  0.  0. ]\n",
      "[I 250519 10:28:43 3690967061:135] Iter:11|loss:2.4612369537353516\n",
      "[I 250519 10:28:43 3690967061:178] Evaluate 11|OA:0.33181818181818185|MACC:0.3318181818181818|Kappa:0.3|MIOU:0.18451377312058428|IOU:[0.2308 0.15   0.     0.     0.     0.4211 0.     0.     0.7    0.5294\n",
      "     0.1333 0.3529 0.     0.1    0.1538 0.5833 0.32   0.     0.3846 0.\n",
      "     0.     0.    ]|ACC:[0.9 0.3 0.  0.  0.  0.8 0.  0.  0.7 0.9 0.8 0.6 0.  0.1 0.2 0.7 0.8 0.\n",
      "     0.5 0.  0.  0. ]\n",
      "[I 250519 10:28:44 3690967061:135] Iter:12|loss:2.416980028152466\n",
      "[I 250519 10:28:45 3690967061:178] Evaluate 12|OA:0.37727272727272726|MACC:0.3772727272727273|Kappa:0.34761904761904755|MIOU:0.22288468045985363|IOU:[0.2727 0.24   0.     0.     0.0588 0.4444 0.     0.     0.9    0.6\n",
      "     0.1475 0.4444 0.     0.1    0.2143 0.6923 0.3889 0.     0.4    0.\n",
      "     0.     0.    ]|ACC:[0.9 0.6 0.  0.  0.1 0.8 0.  0.  0.9 0.9 0.9 0.8 0.  0.1 0.3 0.9 0.7 0.\n",
      "     0.4 0.  0.  0. ]\n",
      "[I 250519 10:28:46 3690967061:135] Iter:13|loss:2.3777554035186768\n",
      "[I 250519 10:28:46 3690967061:178] Evaluate 13|OA:0.37272727272727274|MACC:0.3727272727272727|Kappa:0.34285714285714286|MIOU:0.22182122340924518|IOU:[0.25   0.2593 0.     0.     0.0526 0.4444 0.     0.     0.9    0.5625\n",
      "     0.1552 0.3889 0.     0.1    0.2143 0.6154 0.4375 0.     0.5    0.\n",
      "     0.     0.    ]|ACC:[0.8 0.7 0.  0.  0.1 0.8 0.  0.  0.9 0.9 0.9 0.7 0.  0.1 0.3 0.8 0.7 0.\n",
      "     0.5 0.  0.  0. ]\n",
      "[I 250519 10:28:47 3690967061:135] Iter:14|loss:2.335592031478882\n",
      "[I 250519 10:28:48 3690967061:178] Evaluate 14|OA:0.38181818181818183|MACC:0.3818181818181818|Kappa:0.35238095238095235|MIOU:0.23627235455336193|IOU:[0.2581 0.2593 0.     0.     0.0476 0.4444 0.1333 0.     0.9    0.6429\n",
      "     0.15   0.4118 0.     0.1    0.2143 0.5455 0.5    0.0909 0.5    0.\n",
      "     0.     0.    ]|ACC:[0.8 0.7 0.  0.  0.1 0.8 0.2 0.  0.9 0.9 0.9 0.7 0.  0.1 0.3 0.6 0.8 0.1\n",
      "     0.5 0.  0.  0. ]\n",
      "[I 250519 10:28:49 3690967061:135] Iter:15|loss:2.2930819988250732\n",
      "[I 250519 10:28:49 3690967061:178] Evaluate 15|OA:0.39090909090909093|MACC:0.390909090909091|Kappa:0.3619047619047619|MIOU:0.2505463329857859|IOU:[0.2581 0.2759 0.     0.     0.0417 0.5    0.125  0.     0.8182 0.6923\n",
      "     0.1429 0.4375 0.     0.2727 0.2143 0.7273 0.6154 0.0909 0.3    0.\n",
      "     0.     0.    ]|ACC:[0.8 0.8 0.  0.  0.1 0.8 0.2 0.  0.9 0.9 0.8 0.7 0.  0.3 0.3 0.8 0.8 0.1\n",
      "     0.3 0.  0.  0. ]\n",
      "[I 250519 10:28:50 3690967061:135] Iter:16|loss:2.250047445297241\n",
      "[I 250519 10:28:51 3690967061:178] Evaluate 16|OA:0.4090909090909091|MACC:0.4090909090909091|Kappa:0.38095238095238093|MIOU:0.2666104167514826|IOU:[0.2759 0.3    0.     0.     0.04   0.5333 0.1333 0.     0.8182 0.75\n",
      "     0.1636 0.4667 0.     0.4    0.2143 0.6429 0.5455 0.0909 0.4    0.\n",
      "     0.0909 0.    ]|ACC:[0.8 0.9 0.  0.  0.1 0.8 0.2 0.  0.9 0.9 0.9 0.7 0.  0.4 0.3 0.9 0.6 0.1\n",
      "     0.4 0.  0.1 0. ]\n",
      "[I 250519 10:28:52 3690967061:135] Iter:17|loss:2.2102861404418945\n",
      "[I 250519 10:28:52 3690967061:178] Evaluate 17|OA:0.44545454545454544|MACC:0.4454545454545454|Kappa:0.419047619047619|MIOU:0.3074739050101922|IOU:[0.3077 0.2941 0.     0.1    0.0357 0.5333 0.1667 0.     0.8182 0.75\n",
      "     0.1633 0.5333 0.     0.3636 0.5833 0.75   0.7    0.1818 0.4    0.\n",
      "     0.0833 0.    ]|ACC:[0.8 1.  0.  0.1 0.1 0.8 0.2 0.  0.9 0.9 0.8 0.8 0.  0.4 0.7 0.9 0.7 0.2\n",
      "     0.4 0.  0.1 0. ]\n",
      "[I 250519 10:28:53 3690967061:135] Iter:18|loss:2.17203688621521\n",
      "[I 250519 10:28:53 3690967061:178] Evaluate 18|OA:0.4727272727272727|MACC:0.4727272727272727|Kappa:0.4476190476190476|MIOU:0.32224591424071514|IOU:[0.3636 0.2857 0.     0.     0.069  0.5714 0.0909 0.     0.8182 0.6429\n",
      "     0.2195 0.5333 0.     0.3636 0.6667 0.6364 0.6667 0.3077 0.5    0.\n",
      "     0.1538 0.2   ]|ACC:[0.8 1.  0.  0.  0.2 0.8 0.1 0.  0.9 0.9 0.9 0.8 0.  0.4 0.8 0.7 0.8 0.4\n",
      "     0.5 0.  0.2 0.2]\n",
      "[I 250519 10:28:54 3690967061:135] Iter:19|loss:2.1333117485046387\n",
      "[I 250519 10:28:55 3690967061:178] Evaluate 19|OA:0.5045454545454545|MACC:0.5045454545454546|Kappa:0.4809523809523809|MIOU:0.3522138571350448|IOU:[0.4    0.2857 0.     0.     0.0645 0.6154 0.1    0.0833 0.9    0.6429\n",
      "     0.2812 0.5714 0.     0.5    0.625  0.6364 0.6667 0.3333 0.5    0.\n",
      "     0.1429 0.4   ]|ACC:[0.8 1.  0.  0.  0.2 0.8 0.1 0.1 0.9 0.9 0.9 0.8 0.  0.5 1.  0.7 0.8 0.5\n",
      "     0.5 0.  0.2 0.4]\n",
      "[I 250519 10:28:56 3690967061:135] Iter:20|loss:2.094114065170288\n",
      "[I 250519 10:28:56 3690967061:178] Evaluate 20|OA:0.5136363636363637|MACC:0.5136363636363636|Kappa:0.49047619047619045|MIOU:0.3767021869836272|IOU:[0.3889 0.2857 0.     0.     0.0588 0.6154 0.2    0.0714 0.9    0.75\n",
      "     0.2759 0.5    0.     0.6    0.625  0.75   0.7    0.3125 0.5    0.\n",
      "     0.1538 0.6   ]|ACC:[0.7 1.  0.  0.  0.2 0.8 0.2 0.1 0.9 0.9 0.8 0.7 0.  0.6 1.  0.9 0.7 0.5\n",
      "     0.5 0.  0.2 0.6]\n",
      "[I 250519 10:28:57 3690967061:135] Iter:21|loss:2.0547900199890137\n",
      "[I 250519 10:28:58 3690967061:178] Evaluate 21|OA:0.5363636363636364|MACC:0.5363636363636363|Kappa:0.5142857142857142|MIOU:0.39429547725002273|IOU:[0.4667 0.3125 0.     0.     0.1714 0.6667 0.1818 0.0667 0.9    0.75\n",
      "     0.2857 0.5385 0.     0.7    0.4762 0.6667 0.6364 0.3125 0.6    0.\n",
      "     0.1429 0.8   ]|ACC:[0.7 1.  0.  0.  0.6 0.8 0.2 0.1 0.9 0.9 0.6 0.7 0.  0.7 1.  0.8 0.7 0.5\n",
      "     0.6 0.  0.2 0.8]\n",
      "[I 250519 10:28:59 3690967061:135] Iter:22|loss:2.017651319503784\n",
      "[I 250519 10:28:59 3690967061:178] Evaluate 22|OA:0.5590909090909091|MACC:0.5590909090909091|Kappa:0.5380952380952381|MIOU:0.4207294189676752|IOU:[0.5    0.3226 0.     0.     0.1818 0.7273 0.1818 0.1538 0.9    0.75\n",
      "     0.3529 0.5385 0.     0.8    0.4545 0.75   0.7    0.4375 0.6    0.\n",
      "     0.1053 0.8   ]|ACC:[0.7 1.  0.  0.  0.6 0.8 0.2 0.2 0.9 0.9 0.6 0.7 0.  0.8 1.  0.9 0.7 0.7\n",
      "     0.6 0.  0.2 0.8]\n",
      "[I 250519 10:29:00 3690967061:135] Iter:23|loss:1.9833884239196777\n",
      "[I 250519 10:29:01 3690967061:178] Evaluate 23|OA:0.5681818181818182|MACC:0.5681818181818182|Kappa:0.5476190476190477|MIOU:0.4215057471741964|IOU:[0.5    0.3704 0.     0.     0.2    0.7273 0.2    0.1667 0.9    0.6923\n",
      "     0.3333 0.5385 0.     0.8    0.4    0.6923 0.7    0.4706 0.6    0.\n",
      "     0.1818 0.8   ]|ACC:[0.7 1.  0.  0.  0.6 0.8 0.2 0.2 0.9 0.9 0.5 0.7 0.  0.8 1.  0.9 0.7 0.8\n",
      "     0.6 0.  0.4 0.8]\n",
      "[I 250519 10:29:01 3690967061:135] Iter:24|loss:1.9485836029052734\n",
      "[I 250519 10:29:02 3690967061:178] Evaluate 24|OA:0.5681818181818182|MACC:0.5681818181818182|Kappa:0.5476190476190477|MIOU:0.4131809565391071|IOU:[0.5833 0.3448 0.     0.     0.2222 0.6667 0.     0.1667 0.8182 0.5625\n",
      "     0.4167 0.5385 0.     0.7    0.4167 0.7273 0.8182 0.5    0.6    0.\n",
      "     0.2083 0.8   ]|ACC:[0.7 1.  0.  0.  0.6 0.8 0.  0.2 0.9 0.9 0.5 0.7 0.  0.7 1.  0.8 0.9 0.9\n",
      "     0.6 0.  0.5 0.8]\n",
      "[I 250519 10:29:03 3690967061:135] Iter:25|loss:1.9139454364776611\n",
      "[I 250519 10:29:03 3690967061:178] Evaluate 25|OA:0.5636363636363636|MACC:0.5636363636363636|Kappa:0.5428571428571428|MIOU:0.4107494703959517|IOU:[0.6364 0.3226 0.     0.     0.2609 0.7273 0.1818 0.1818 0.9    0.5294\n",
      "     0.2727 0.5385 0.     0.7    0.4167 0.6429 0.6    0.45   0.6    0.0833\n",
      "     0.1923 0.8   ]|ACC:[0.7 1.  0.  0.  0.6 0.8 0.2 0.2 0.9 0.9 0.3 0.7 0.  0.7 1.  0.9 0.6 0.9\n",
      "     0.6 0.1 0.5 0.8]\n",
      "[I 250519 10:29:04 3690967061:135] Iter:26|loss:1.880033016204834\n",
      "[I 250519 10:29:05 3690967061:178] Evaluate 26|OA:0.5727272727272728|MACC:0.5727272727272728|Kappa:0.5523809523809524|MIOU:0.4352159508750999|IOU:[0.7    0.2778 0.     0.     0.1364 0.7273 0.0909 0.1818 0.8182 0.5294\n",
      "     0.3636 0.6667 0.     0.8    0.4348 0.7    0.75   0.5294 0.7    0.0833\n",
      "     0.1852 0.9   ]|ACC:[0.7 1.  0.  0.  0.3 0.8 0.1 0.2 0.9 0.9 0.4 0.8 0.  0.8 1.  0.7 0.9 0.9\n",
      "     0.7 0.1 0.5 0.9]\n",
      "[I 250519 10:29:06 3690967061:135] Iter:27|loss:1.8490493297576904\n",
      "[I 250519 10:29:06 3690967061:178] Evaluate 27|OA:0.5590909090909091|MACC:0.5590909090909091|Kappa:0.5380952380952381|MIOU:0.41439960515902163|IOU:[0.7    0.2857 0.     0.0909 0.1429 0.7273 0.1818 0.1818 0.9    0.5294\n",
      "     0.2727 0.5385 0.1    0.7    0.4348 0.5625 0.4    0.5    0.7    0.0833\n",
      "     0.1852 0.9   ]|ACC:[0.7 1.  0.  0.1 0.3 0.8 0.2 0.2 0.9 0.9 0.3 0.7 0.1 0.7 1.  0.9 0.4 0.9\n",
      "     0.7 0.1 0.5 0.9]\n",
      "[I 250519 10:29:07 3690967061:135] Iter:28|loss:1.8178622722625732\n",
      "[I 250519 10:29:08 3690967061:178] Evaluate 28|OA:0.5909090909090909|MACC:0.5909090909090909|Kappa:0.5714285714285715|MIOU:0.45347867131318653|IOU:[0.7    0.303  0.     0.     0.1739 0.7273 0.0909 0.1667 0.8182 0.5294\n",
      "     0.3636 0.7273 0.2    0.8    0.4762 0.6    0.6923 0.5625 0.8    0.1667\n",
      "     0.1786 0.9   ]|ACC:[0.7 1.  0.  0.  0.4 0.8 0.1 0.2 0.9 0.9 0.4 0.8 0.2 0.8 1.  0.6 0.9 0.9\n",
      "     0.8 0.2 0.5 0.9]\n",
      "[I 250519 10:29:09 3690967061:135] Iter:29|loss:1.7789939641952515\n",
      "[I 250519 10:29:09 3690967061:178] Evaluate 29|OA:0.6227272727272727|MACC:0.6227272727272727|Kappa:0.6047619047619047|MIOU:0.47963339270157446|IOU:[0.7    0.3704 0.2727 0.     0.2381 0.7273 0.0909 0.1818 0.8182 0.5\n",
      "     0.3636 0.6154 0.4    0.7    0.4762 0.8    0.8182 0.5625 0.6    0.1667\n",
      "     0.25   0.9   ]|ACC:[0.7 1.  0.3 0.  0.5 0.8 0.1 0.2 0.9 0.9 0.4 0.8 0.4 0.7 1.  0.8 0.9 0.9\n",
      "     0.6 0.2 0.7 0.9]\n",
      "[I 250519 10:29:10 3690967061:135] Iter:30|loss:1.7427129745483398\n",
      "[I 250519 10:29:11 3690967061:178] Evaluate 30|OA:0.6636363636363637|MACC:0.6636363636363637|Kappa:0.6476190476190476|MIOU:0.5232875484668214|IOU:[0.7    0.4348 0.4    0.2    0.2632 0.7273 0.0909 0.1667 0.9    0.5294\n",
      "     0.3636 0.6364 0.4    0.8    0.5263 0.75   0.8    0.5    0.9    0.1667\n",
      "     0.3571 0.9   ]|ACC:[0.7 1.  0.4 0.2 0.5 0.8 0.1 0.2 0.9 0.9 0.4 0.7 0.4 0.8 1.  0.9 0.8 0.9\n",
      "     0.9 0.2 1.  0.9]\n",
      "[I 250519 10:29:11 3690967061:135] Iter:31|loss:1.7133715152740479\n",
      "[I 250519 10:29:12 3690967061:178] Evaluate 31|OA:0.6590909090909091|MACC:0.6590909090909092|Kappa:0.6428571428571428|MIOU:0.5122307915370116|IOU:[0.7    0.4545 0.5    0.2    0.2632 0.7273 0.1667 0.2    0.75   0.6\n",
      "     0.2727 0.7273 0.4    0.8    0.5263 0.5    0.7143 0.6    0.7273 0.1538\n",
      "     0.2857 1.    ]|ACC:[0.7 1.  0.6 0.2 0.5 0.8 0.2 0.2 0.9 0.9 0.3 0.8 0.4 0.8 1.  0.5 1.  0.9\n",
      "     0.8 0.2 0.8 1. ]\n",
      "[I 250519 10:29:13 3690967061:135] Iter:32|loss:1.6854453086853027\n",
      "[I 250519 10:29:13 3690967061:178] Evaluate 32|OA:0.6681818181818182|MACC:0.6681818181818183|Kappa:0.6523809523809524|MIOU:0.5257902290972937|IOU:[0.7    0.4762 0.5833 0.2    0.2632 0.7273 0.1667 0.1818 0.8182 0.6429\n",
      "     0.3333 0.5833 0.4    0.7273 0.5882 0.75   0.8    0.5294 0.7273 0.0833\n",
      "     0.2857 1.    ]|ACC:[0.7 1.  0.7 0.2 0.5 0.8 0.2 0.2 0.9 0.9 0.4 0.7 0.4 0.8 1.  0.9 0.8 0.9\n",
      "     0.8 0.1 0.8 1. ]\n",
      "[I 250519 10:29:14 3690967061:135] Iter:33|loss:1.6487400531768799\n",
      "[I 250519 10:29:15 3690967061:178] Evaluate 33|OA:0.6863636363636364|MACC:0.6863636363636364|Kappa:0.6714285714285715|MIOU:0.5561865472926548|IOU:[0.7    0.5882 0.5385 0.1    0.2857 0.7273 0.1667 0.1818 0.9    0.6429\n",
      "     0.3333 0.6364 0.4    0.7273 0.5263 0.9    1.     0.5294 0.9    0.1667\n",
      "     0.2857 1.    ]|ACC:[0.7 1.  0.7 0.1 0.6 0.8 0.2 0.2 0.9 0.9 0.4 0.7 0.4 0.8 1.  0.9 1.  0.9\n",
      "     0.9 0.2 0.8 1. ]\n",
      "[I 250519 10:29:16 3690967061:135] Iter:34|loss:1.6140162944793701\n",
      "[I 250519 10:29:16 3690967061:178] Evaluate 34|OA:0.6772727272727272|MACC:0.6772727272727272|Kappa:0.6619047619047619|MIOU:0.5414293371512623|IOU:[0.7    0.5882 0.5    0.1    0.2857 0.7273 0.25   0.1818 0.8182 0.6923\n",
      "     0.3333 0.7273 0.4    0.8    0.5    0.7    0.8333 0.6429 0.7273 0.1538\n",
      "     0.25   1.    ]|ACC:[0.7 1.  0.7 0.1 0.6 0.8 0.3 0.2 0.9 0.9 0.4 0.8 0.4 0.8 1.  0.7 1.  0.9\n",
      "     0.8 0.2 0.7 1. ]\n",
      "[I 250519 10:29:17 3690967061:135] Iter:35|loss:1.58645498752594\n",
      "[I 250519 10:29:18 3690967061:178] Evaluate 35|OA:0.6954545454545454|MACC:0.6954545454545454|Kappa:0.680952380952381|MIOU:0.563886740858666|IOU:[0.7    0.5882 0.5833 0.1    0.2857 0.7273 0.25   0.1818 0.9    0.8182\n",
      "     0.3333 0.6667 0.4    0.7273 0.5556 0.9091 0.9    0.5625 0.8182 0.0769\n",
      "     0.3214 1.    ]|ACC:[0.7 1.  0.7 0.1 0.6 0.8 0.3 0.2 0.9 0.9 0.4 0.8 0.4 0.8 1.  1.  0.9 0.9\n",
      "     0.9 0.1 0.9 1. ]\n",
      "[I 250519 10:29:19 3690967061:135] Iter:36|loss:1.554771065711975\n",
      "[I 250519 10:29:19 3690967061:178] Evaluate 36|OA:0.6954545454545454|MACC:0.6954545454545454|Kappa:0.680952380952381|MIOU:0.5570318138799001|IOU:[0.7    0.6667 0.5833 0.1    0.3333 0.7273 0.25   0.1818 0.9    0.75\n",
      "     0.3333 0.7273 0.4    0.7273 0.5263 0.7    0.8333 0.5625 0.8182 0.0769\n",
      "     0.3571 1.    ]|ACC:[0.7 1.  0.7 0.1 0.7 0.8 0.3 0.2 0.9 0.9 0.4 0.8 0.4 0.8 1.  0.7 1.  0.9\n",
      "     0.9 0.1 1.  1. ]\n",
      "[I 250519 10:29:20 3690967061:135] Iter:37|loss:1.52164626121521\n",
      "[I 250519 10:29:21 3690967061:178] Evaluate 37|OA:0.6954545454545454|MACC:0.6954545454545455|Kappa:0.680952380952381|MIOU:0.5681528067891704|IOU:[0.7    0.7143 0.4667 0.     0.2857 0.8    0.3846 0.1818 0.75   0.8182\n",
      "     0.25   0.7273 0.4    0.8182 0.5556 0.9    1.     0.6923 0.6667 0.0667\n",
      "     0.3214 1.    ]|ACC:[0.7 1.  0.7 0.  0.6 0.8 0.5 0.2 0.9 0.9 0.3 0.8 0.4 0.9 1.  0.9 1.  0.9\n",
      "     0.8 0.1 0.9 1. ]\n",
      "[I 250519 10:29:21 3690967061:135] Iter:38|loss:1.4941846132278442\n",
      "[I 250519 10:29:22 3690967061:178] Evaluate 38|OA:0.7181818181818181|MACC:0.7181818181818183|Kappa:0.7047619047619047|MIOU:0.5924870361367688|IOU:[0.7    0.7143 0.5    0.1    0.381  0.7273 0.3636 0.1818 0.9    0.8182\n",
      "     0.4167 0.7273 0.4    0.7273 0.625  1.     1.     0.5294 0.8182 0.0714\n",
      "     0.3333 1.    ]|ACC:[0.7 1.  0.7 0.1 0.8 0.8 0.4 0.2 0.9 0.9 0.5 0.8 0.4 0.8 1.  1.  1.  0.9\n",
      "     0.9 0.1 0.9 1. ]\n",
      "[I 250519 10:29:23 3690967061:135] Iter:39|loss:1.4632413387298584\n",
      "[I 250519 10:29:24 3690967061:178] Evaluate 39|OA:0.7227272727272728|MACC:0.7227272727272728|Kappa:0.7095238095238096|MIOU:0.5975501770956316|IOU:[0.7    0.7143 0.5    0.     0.381  0.8    0.3077 0.1818 0.8182 1.\n",
      "     0.3636 0.75   0.4    0.8182 0.7143 1.     1.     0.6    0.6923 0.0714\n",
      "     0.3333 1.    ]|ACC:[0.7 1.  0.7 0.  0.8 0.8 0.4 0.2 0.9 1.  0.4 0.9 0.4 0.9 1.  1.  1.  0.9\n",
      "     0.9 0.1 0.9 1. ]\n",
      "[I 250519 10:29:24 3690967061:135] Iter:40|loss:1.4303210973739624\n",
      "[I 250519 10:29:25 3690967061:178] Evaluate 40|OA:0.7|MACC:0.7000000000000001|Kappa:0.6857142857142857|MIOU:0.5691074077437714|IOU:[0.7    0.7692 0.4667 0.     0.3636 0.8    0.3636 0.2    0.8182 0.9\n",
      "     0.2727 0.6364 0.3636 0.8182 0.4762 0.9    1.     0.6    0.75   0.0667\n",
      "     0.3462 0.9091]|ACC:[0.7 1.  0.7 0.  0.8 0.8 0.4 0.2 0.9 0.9 0.3 0.7 0.4 0.9 1.  0.9 1.  0.9\n",
      "     0.9 0.1 0.9 1. ]\n",
      "[I 250519 10:29:26 3690967061:135] Iter:41|loss:1.4103195667266846\n",
      "[I 250519 10:29:26 3690967061:178] Evaluate 41|OA:0.7227272727272728|MACC:0.7227272727272728|Kappa:0.7095238095238096|MIOU:0.5897031756122664|IOU:[0.7    0.7143 0.5    0.     0.381  0.7273 0.25   0.2727 0.75   1.\n",
      "     0.3846 0.7692 0.4    0.7273 0.7143 0.9    1.     0.75   0.6923 0.0714\n",
      "     0.36   0.9091]|ACC:[0.7 1.  0.7 0.  0.8 0.8 0.3 0.3 0.9 1.  0.5 1.  0.4 0.8 1.  0.9 1.  0.9\n",
      "     0.9 0.1 0.9 1. ]\n",
      "[I 250519 10:29:27 3690967061:135] Iter:42|loss:1.3900903463363647\n",
      "[I 250519 10:29:28 3690967061:178] Evaluate 42|OA:0.7136363636363636|MACC:0.7136363636363637|Kappa:0.7|MIOU:0.5761015277058058|IOU:[0.7    0.7692 0.5385 0.     0.4091 0.8    0.3333 0.2    0.9    0.9091\n",
      "     0.4167 0.6364 0.3077 0.8182 0.7143 0.8    0.8333 0.5294 0.75   0.\n",
      "     0.4    0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.4 0.2 0.9 1.  0.5 0.7 0.4 0.9 1.  0.8 1.  0.9\n",
      "     0.9 0.  1.  1. ]\n",
      "[I 250519 10:29:29 3690967061:135] Iter:43|loss:1.3558177947998047\n",
      "[I 250519 10:29:29 3690967061:178] Evaluate 43|OA:0.7454545454545455|MACC:0.7454545454545454|Kappa:0.7333333333333334|MIOU:0.6180130475585021|IOU:[0.7    0.7143 0.5833 0.     0.4091 0.8    0.5455 0.2727 0.75   1.\n",
      "     0.5    0.7273 0.3333 0.8182 0.7143 0.9    1.     0.75   0.6923 0.0769\n",
      "     0.4    0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.6 0.3 0.9 1.  0.6 0.8 0.4 0.9 1.  0.9 1.  0.9\n",
      "     0.9 0.1 1.  1. ]\n",
      "[I 250519 10:29:30 3690967061:135] Iter:44|loss:1.3300845623016357\n",
      "[I 250519 10:29:31 3690967061:178] Evaluate 44|OA:0.740909090909091|MACC:0.7409090909090907|Kappa:0.7285714285714286|MIOU:0.6039891926255562|IOU:[0.7    0.7143 0.5833 0.     0.4286 0.8    0.4167 0.4545 0.75   1.\n",
      "     0.4545 0.6667 0.3333 0.8182 0.7143 0.8    0.9091 0.6429 0.6923 0.0833\n",
      "     0.4167 0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.5 0.5 0.9 1.  0.5 0.8 0.4 0.9 1.  0.8 1.  0.9\n",
      "     0.9 0.1 1.  1. ]\n",
      "[I 250519 10:29:31 3690967061:135] Iter:45|loss:1.2957746982574463\n",
      "[I 250519 10:29:32 3690967061:178] Evaluate 45|OA:0.7272727272727273|MACC:0.7272727272727273|Kappa:0.7142857142857143|MIOU:0.5936319362455725|IOU:[0.7    0.7143 0.5833 0.     0.4286 0.8    0.3333 0.2727 0.8182 0.9091\n",
      "     0.4167 0.7273 0.2857 0.8182 0.7143 0.9    1.     0.5625 0.75   0.\n",
      "     0.4167 0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.4 0.3 0.9 1.  0.5 0.8 0.4 0.9 1.  0.9 1.  0.9\n",
      "     0.9 0.  1.  1. ]\n",
      "[I 250519 10:29:33 3690967061:135] Iter:46|loss:1.2776583433151245\n",
      "[I 250519 10:29:34 3690967061:178] Evaluate 46|OA:0.75|MACC:0.75|Kappa:0.7380952380952381|MIOU:0.6220446549497932|IOU:[0.7    0.7143 0.5833 0.     0.4286 0.8    0.5455 0.25   0.6923 1.\n",
      "     0.5    0.8    0.2857 0.8182 0.7143 0.9    1.     0.75   0.6923 0.1667\n",
      "     0.4348 0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.6 0.3 0.9 1.  0.6 0.8 0.4 0.9 1.  0.9 1.  0.9\n",
      "     0.9 0.2 1.  1. ]\n",
      "[I 250519 10:29:34 3690967061:135] Iter:47|loss:1.251235008239746\n",
      "[I 250519 10:29:35 3690967061:178] Evaluate 47|OA:0.75|MACC:0.75|Kappa:0.7380952380952381|MIOU:0.618038812307587|IOU:[0.7    0.6667 0.7    0.     0.4091 0.8    0.4615 0.4167 0.75   1.\n",
      "     0.4545 0.8182 0.3333 0.8182 0.7143 0.7    0.8333 0.8182 0.6923 0.1667\n",
      "     0.4348 0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.6 0.5 0.9 1.  0.5 0.9 0.4 0.9 1.  0.7 1.  0.9\n",
      "     0.9 0.2 1.  1. ]\n",
      "[I 250519 10:29:36 3690967061:135] Iter:48|loss:1.225311040878296\n",
      "[I 250519 10:29:36 3690967061:178] Evaluate 48|OA:0.75|MACC:0.75|Kappa:0.7380952380952381|MIOU:0.6235878087656742|IOU:[0.7    0.6667 0.7    0.     0.4091 0.8    0.3846 0.4167 0.75   1.\n",
      "     0.3846 0.7273 0.3333 0.8182 0.8333 0.9    1.     0.6923 0.6923 0.1667\n",
      "     0.4348 0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.5 0.5 0.9 1.  0.5 0.8 0.4 0.9 1.  0.9 1.  0.9\n",
      "     0.9 0.2 1.  1. ]\n",
      "[I 250519 10:29:37 3690967061:135] Iter:49|loss:1.205691933631897\n",
      "[I 250519 10:29:38 3690967061:178] Evaluate 49|OA:0.7772727272727272|MACC:0.7772727272727273|Kappa:0.7666666666666666|MIOU:0.6556102987921169|IOU:[0.7    0.6667 0.7    0.     0.4091 0.8    0.5    0.4545 0.75   1.\n",
      "     0.5    0.8182 0.3333 0.8182 0.7692 0.9    1.     0.8182 0.6923 0.3846\n",
      "     0.5    0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.6 0.5 0.9 1.  0.6 0.9 0.4 0.9 1.  0.9 1.  0.9\n",
      "     0.9 0.5 1.  1. ]\n",
      "[I 250519 10:29:39 3690967061:135] Iter:50|loss:1.1796281337738037\n",
      "[I 250519 10:29:39 3690967061:178] Evaluate 50|OA:0.7727272727272727|MACC:0.7727272727272727|Kappa:0.7619047619047619|MIOU:0.6493820772528905|IOU:[0.7    0.6667 0.7    0.     0.4091 0.8    0.5    0.4167 0.75   1.\n",
      "     0.5    0.8182 0.4167 0.8182 0.7143 0.9    1.     0.8182 0.6923 0.2308\n",
      "     0.5263 0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.6 0.5 0.9 1.  0.6 0.9 0.5 0.9 1.  0.9 1.  0.9\n",
      "     0.9 0.3 1.  1. ]\n",
      "[I 250519 10:29:40 3690967061:135] Iter:51|loss:1.1603952646255493\n",
      "[I 250519 10:29:41 3690967061:178] Evaluate 51|OA:0.7727272727272727|MACC:0.7727272727272727|Kappa:0.7619047619047619|MIOU:0.6493413152504061|IOU:[0.7    0.6667 0.7    0.     0.4091 0.8    0.4615 0.3846 0.75   1.\n",
      "     0.4615 0.7273 0.4545 0.8182 0.7692 0.9    1.     0.8182 0.6923 0.3077\n",
      "     0.5556 0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.6 0.5 0.9 1.  0.6 0.8 0.5 0.9 1.  0.9 1.  0.9\n",
      "     0.9 0.4 1.  1. ]\n",
      "[I 250519 10:29:41 3690967061:135] Iter:52|loss:1.1351832151412964\n",
      "[I 250519 10:29:42 3690967061:178] Evaluate 52|OA:0.7863636363636364|MACC:0.7863636363636363|Kappa:0.7761904761904762|MIOU:0.6645571600117054|IOU:[0.7    0.6667 0.7    0.     0.4286 0.8    0.5    0.4545 0.75   1.\n",
      "     0.4615 0.8182 0.4167 0.8182 0.7692 0.9    1.     0.8182 0.6923 0.4615\n",
      "     0.5556 0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.6 0.5 0.9 1.  0.6 0.9 0.5 0.9 1.  0.9 1.  0.9\n",
      "     0.9 0.6 1.  1. ]\n",
      "[I 250519 10:29:43 3690967061:135] Iter:53|loss:1.1162315607070923\n",
      "[I 250519 10:29:43 3690967061:178] Evaluate 53|OA:0.7863636363636364|MACC:0.7863636363636363|Kappa:0.7761904761904762|MIOU:0.6603339841976206|IOU:[0.7    0.6667 0.7    0.     0.4286 0.8    0.5    0.3846 0.75   1.\n",
      "     0.4615 0.8182 0.6    0.9091 0.7692 0.7    0.8333 0.8182 0.6923 0.4615\n",
      "     0.625  0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.6 0.5 0.9 1.  0.6 0.9 0.6 1.  1.  0.7 1.  0.9\n",
      "     0.9 0.6 1.  1. ]\n",
      "[I 250519 10:29:44 3690967061:135] Iter:54|loss:1.0979795455932617\n",
      "[I 250519 10:29:45 3690967061:178] Evaluate 54|OA:0.7772727272727272|MACC:0.7772727272727273|Kappa:0.7666666666666666|MIOU:0.6468830412012229|IOU:[0.7    0.6667 0.7    0.     0.4286 0.8    0.4615 0.4167 0.75   1.\n",
      "     0.4615 0.8    0.5455 0.9091 0.7692 0.6923 0.7    0.8182 0.6923 0.4615\n",
      "     0.625  0.8333]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.6 0.5 0.9 1.  0.6 0.8 0.6 1.  1.  0.9 0.7 0.9\n",
      "     0.9 0.6 1.  1. ]\n",
      "[I 250519 10:29:46 3690967061:135] Iter:55|loss:1.0901243686676025\n",
      "[I 250519 10:29:46 3690967061:178] Evaluate 55|OA:0.7681818181818182|MACC:0.7681818181818181|Kappa:0.7571428571428571|MIOU:0.6350221747949019|IOU:[0.7    0.6667 0.7    0.     0.4286 0.8    0.4286 0.3846 0.6923 1.\n",
      "     0.4615 0.7273 0.5455 0.9091 0.8333 0.4    0.6667 0.9    0.6923 0.5\n",
      "     0.625  0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.6 0.5 0.9 1.  0.6 0.8 0.6 1.  1.  0.4 1.  0.9\n",
      "     0.9 0.6 1.  1. ]\n",
      "[I 250519 10:29:47 3690967061:135] Iter:56|loss:1.0962367057800293\n",
      "[I 250519 10:29:48 3690967061:178] Evaluate 56|OA:0.7909090909090909|MACC:0.7909090909090909|Kappa:0.780952380952381|MIOU:0.6704155692792056|IOU:[0.7    0.6667 0.7    0.     0.4286 0.8    0.5    0.4167 0.75   1.\n",
      "     0.4615 0.8182 0.5    0.9091 0.7692 0.9    1.     0.8182 0.6923 0.3846\n",
      "     0.625  0.9091]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.6 0.5 0.9 1.  0.6 0.9 0.6 1.  1.  0.9 1.  0.9\n",
      "     0.9 0.5 1.  1. ]\n",
      "[I 250519 10:29:49 3690967061:135] Iter:57|loss:1.0601856708526611\n",
      "[I 250519 10:29:49 3690967061:178] Evaluate 57|OA:0.7909090909090909|MACC:0.7909090909090909|Kappa:0.780952380952381|MIOU:0.6727821421003239|IOU:[0.7    0.6667 0.7    0.     0.4286 0.8    0.4286 0.4167 0.8182 1.\n",
      "     0.4615 0.8    0.5455 0.9091 0.7143 0.9    1.     0.9    0.6923 0.4615\n",
      "     0.625  0.8333]|ACC:[0.7 1.  0.7 0.  0.9 0.8 0.6 0.5 0.9 1.  0.6 0.8 0.6 1.  1.  0.9 1.  0.9\n",
      "     0.9 0.6 1.  1. ]\n",
      "[I 250519 10:29:50 3690967061:135] Iter:58|loss:1.032270908355713\n",
      "[I 250519 10:29:51 3690967061:178] Evaluate 58|OA:0.7863636363636364|MACC:0.7863636363636363|Kappa:0.7761904761904762|MIOU:0.6596816062725153|IOU:[0.7    0.6667 0.7    0.1    0.45   0.8    0.4615 0.4615 0.6923 1.\n",
      "     0.4615 0.8    0.5455 0.9091 0.7692 0.6    0.7692 0.9    0.6923 0.5\n",
      "     0.625  0.9091]|ACC:[0.7 1.  0.7 0.1 0.9 0.8 0.6 0.6 0.9 1.  0.6 0.8 0.6 1.  1.  0.6 1.  0.9\n",
      "     0.9 0.6 1.  1. ]\n",
      "[I 250519 10:29:51 3690967061:135] Iter:59|loss:1.0228298902511597\n",
      "[I 250519 10:29:52 3690967061:178] Evaluate 59|OA:0.7954545454545454|MACC:0.7954545454545454|Kappa:0.7857142857142857|MIOU:0.676957512184785|IOU:[0.7    0.7692 0.7    0.     0.4545 0.8    0.5833 0.3846 0.75   1.\n",
      "     0.4615 0.8182 0.5    0.9091 0.8333 0.8    0.9091 0.8182 0.6923 0.3846\n",
      "     0.625  1.    ]|ACC:[0.7 1.  0.7 0.  1.  0.8 0.7 0.5 0.9 1.  0.6 0.9 0.6 1.  1.  0.8 1.  0.9\n",
      "     0.9 0.5 1.  1. ]\n",
      "[I 250519 10:29:53 3690967061:135] Iter:60|loss:0.991198718547821\n",
      "[I 250519 10:29:53 3690967061:178] Evaluate 60|OA:0.8136363636363636|MACC:0.8136363636363636|Kappa:0.8047619047619048|MIOU:0.7045692943420216|IOU:[0.7    0.6667 0.7    0.1    0.45   0.8    0.5833 0.5455 0.8182 1.\n",
      "     0.4615 0.8182 0.5    0.9091 0.7692 1.     1.     0.9    0.6923 0.4615\n",
      "     0.625  1.    ]|ACC:[0.7 1.  0.7 0.1 0.9 0.8 0.7 0.6 0.9 1.  0.6 0.9 0.6 1.  1.  1.  1.  0.9\n",
      "     0.9 0.6 1.  1. ]\n",
      "[I 250519 10:29:54 3690967061:135] Iter:61|loss:0.9691450595855713\n",
      "[I 250519 10:29:55 3690967061:178] Evaluate 61|OA:0.8136363636363636|MACC:0.8136363636363636|Kappa:0.8047619047619048|MIOU:0.7019945963127782|IOU:[0.7    0.6667 0.7    0.3    0.5    0.8    0.4615 0.5    0.8182 1.\n",
      "     0.4615 0.8    0.5455 0.9091 0.7692 1.     1.     0.9    0.6923 0.4615\n",
      "     0.625  0.8333]|ACC:[0.7 1.  0.7 0.3 0.9 0.8 0.6 0.6 0.9 1.  0.6 0.8 0.6 1.  1.  1.  1.  0.9\n",
      "     0.9 0.6 1.  1. ]\n",
      "[I 250519 10:29:56 3690967061:135] Iter:62|loss:0.9506847858428955\n",
      "[I 250519 10:29:56 3690967061:178] Evaluate 62|OA:0.8181818181818182|MACC:0.8181818181818182|Kappa:0.8095238095238095|MIOU:0.7068840449821311|IOU:[0.7    0.7692 0.7    0.3    0.5263 0.8    0.5833 0.5455 0.75   1.\n",
      "     0.4615 0.8182 0.5    0.9091 0.8333 0.8    0.9091 0.9    0.6923 0.4286\n",
      "     0.625  1.    ]|ACC:[0.7 1.  0.7 0.3 1.  0.8 0.7 0.6 0.9 1.  0.6 0.9 0.6 1.  1.  0.8 1.  0.9\n",
      "     0.9 0.6 1.  1. ]\n",
      "[I 250519 10:29:57 3690967061:135] Iter:63|loss:0.9266848564147949\n",
      "[I 250519 10:29:58 3690967061:178] Evaluate 63|OA:0.8227272727272728|MACC:0.8227272727272728|Kappa:0.8142857142857143|MIOU:0.712753175851262|IOU:[0.7    0.7692 0.7    0.3    0.5263 0.8    0.5833 0.5455 0.75   1.\n",
      "     0.4615 0.8182 0.5    0.9091 0.8333 0.8    0.9091 0.9    0.75   0.5\n",
      "     0.625  1.    ]|ACC:[0.7 1.  0.7 0.3 1.  0.8 0.7 0.6 0.9 1.  0.6 0.9 0.6 1.  1.  0.8 1.  0.9\n",
      "     0.9 0.7 1.  1. ]\n",
      "[I 250519 10:29:59 3690967061:135] Iter:64|loss:0.9104740023612976\n",
      "[I 250519 10:29:59 3690967061:178] Evaluate 64|OA:0.8272727272727273|MACC:0.8272727272727273|Kappa:0.819047619047619|MIOU:0.7222958859322495|IOU:[0.7    0.7143 0.7    0.3    0.5    0.8    0.5833 0.5    0.8182 1.\n",
      "     0.4615 0.8182 0.4615 0.9091 0.7692 1.     1.     0.9    0.75   0.5385\n",
      "     0.6667 1.    ]|ACC:[0.7 1.  0.7 0.3 0.9 0.8 0.7 0.6 0.9 1.  0.6 0.9 0.6 1.  1.  1.  1.  0.9\n",
      "     0.9 0.7 1.  1. ]\n",
      "[I 250519 10:30:00 3690967061:135] Iter:65|loss:0.8847926259040833\n",
      "[I 250519 10:30:01 3690967061:178] Evaluate 65|OA:0.8318181818181818|MACC:0.8318181818181819|Kappa:0.8238095238095238|MIOU:0.7259677191495374|IOU:[0.7    0.7692 0.7    0.4    0.5556 0.8    0.5    0.5    0.8182 1.\n",
      "     0.4615 0.9    0.5    0.9091 0.7692 1.     1.     0.9    0.75   0.5385\n",
      "     0.6667 0.8333]|ACC:[0.7 1.  0.7 0.4 1.  0.8 0.6 0.6 0.9 1.  0.6 0.9 0.6 1.  1.  1.  1.  0.9\n",
      "     0.9 0.7 1.  1. ]\n",
      "[I 250519 10:30:01 3690967061:135] Iter:66|loss:0.8693139553070068\n",
      "[I 250519 10:30:02 3690967061:178] Evaluate 66|OA:0.8318181818181818|MACC:0.8318181818181819|Kappa:0.8238095238095238|MIOU:0.7242035742035742|IOU:[0.7    0.7692 0.7    0.4    0.5556 0.8    0.5833 0.5455 0.75   1.\n",
      "     0.4615 0.8182 0.4615 0.9091 0.7692 0.8    0.9091 0.9    0.8182 0.6154\n",
      "     0.6667 1.    ]|ACC:[0.7 1.  0.7 0.4 1.  0.8 0.7 0.6 0.9 1.  0.6 0.9 0.6 1.  1.  0.8 1.  0.9\n",
      "     0.9 0.8 1.  1. ]\n",
      "[I 250519 10:30:03 3690967061:135] Iter:67|loss:0.8442614078521729\n",
      "[I 250519 10:30:03 3690967061:178] Evaluate 67|OA:0.8363636363636363|MACC:0.8363636363636364|Kappa:0.8285714285714285|MIOU:0.7355882952772904|IOU:[0.7    0.8333 0.7    0.4    0.5263 0.8    0.5833 0.5833 0.75   1.\n",
      "     0.4615 0.8182 0.4615 0.9091 0.9091 0.8    0.9091 0.9    0.9    0.5714\n",
      "     0.6667 1.    ]|ACC:[0.7 1.  0.7 0.4 1.  0.8 0.7 0.7 0.9 1.  0.6 0.9 0.6 1.  1.  0.8 1.  0.9\n",
      "     0.9 0.8 1.  1. ]\n",
      "[I 250519 10:30:04 3690967061:135] Iter:68|loss:0.829251766204834\n",
      "[I 250519 10:30:05 3690967061:178] Evaluate 68|OA:0.8409090909090909|MACC:0.8409090909090909|Kappa:0.8333333333333334|MIOU:0.7422860561897995|IOU:[0.7    0.7692 0.7    0.4    0.5882 0.8    0.5833 0.4615 0.75   1.\n",
      "     0.4615 0.9    0.5    0.9091 0.7692 1.     1.     0.9    0.9    0.5714\n",
      "     0.6667 1.    ]|ACC:[0.7 1.  0.7 0.4 1.  0.8 0.7 0.6 0.9 1.  0.6 0.9 0.6 1.  1.  1.  1.  0.9\n",
      "     0.9 0.8 1.  1. ]\n",
      "[I 250519 10:30:06 3690967061:135] Iter:69|loss:0.805518388748169\n",
      "[I 250519 10:30:06 3690967061:178] Evaluate 69|OA:0.85|MACC:0.85|Kappa:0.8428571428571429|MIOU:0.7524645808736717|IOU:[0.7    0.7692 0.7    0.5    0.625  0.8    0.5833 0.5    0.8182 1.\n",
      "     0.4615 0.9    0.5    0.9091 0.7692 1.     1.     0.9    0.9    0.6429\n",
      "     0.6667 0.9091]|ACC:[0.7 1.  0.7 0.5 1.  0.8 0.7 0.6 0.9 1.  0.6 0.9 0.6 1.  1.  1.  1.  0.9\n",
      "     0.9 0.9 1.  1. ]\n",
      "[I 250519 10:30:07 3690967061:135] Iter:70|loss:0.7893952131271362\n",
      "[I 250519 10:30:08 3690967061:178] Evaluate 70|OA:0.8636363636363636|MACC:0.8636363636363636|Kappa:0.8571428571428572|MIOU:0.7724635213271577|IOU:[0.7    0.7692 0.7    0.5    0.625  0.8    0.6667 0.6364 0.8182 1.\n",
      "     0.4615 0.9    0.5385 0.8333 0.8333 1.     1.     0.9    0.9    0.6429\n",
      "     0.7692 1.    ]|ACC:[0.7 1.  0.7 0.5 1.  0.8 0.8 0.7 0.9 1.  0.6 0.9 0.7 1.  1.  1.  1.  0.9\n",
      "     0.9 0.9 1.  1. ]\n",
      "[I 250519 10:30:09 3690967061:135] Iter:71|loss:0.7670685648918152\n",
      "[I 250519 10:30:09 3690967061:178] Evaluate 71|OA:0.8636363636363636|MACC:0.8636363636363636|Kappa:0.8571428571428572|MIOU:0.7701453181399707|IOU:[0.7    0.8333 0.7    0.5    0.5882 0.8    0.5833 0.5833 0.75   1.\n",
      "     0.5455 0.8182 0.6154 0.8333 0.9091 0.9    1.     0.9    0.9    0.7143\n",
      "     0.7692 1.    ]|ACC:[0.7 1.  0.7 0.5 1.  0.8 0.7 0.7 0.9 1.  0.6 0.9 0.8 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:10 3690967061:135] Iter:72|loss:0.7510277032852173\n",
      "[I 250519 10:30:11 3690967061:178] Evaluate 72|OA:0.8681818181818182|MACC:0.8681818181818183|Kappa:0.8619047619047618|MIOU:0.7779913268549632|IOU:[0.7    0.7692 0.7    0.5    0.625  0.8    0.75   0.6364 0.75   1.\n",
      "     0.5    0.9    0.5385 0.9091 0.9091 0.9    1.     0.9    0.9    0.7143\n",
      "     0.7143 1.    ]|ACC:[0.7 1.  0.7 0.5 1.  0.8 0.9 0.7 0.9 1.  0.6 0.9 0.7 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:11 3690967061:135] Iter:73|loss:0.7299525141716003\n",
      "[I 250519 10:30:12 3690967061:178] Evaluate 73|OA:0.8681818181818182|MACC:0.868181818181818|Kappa:0.8619047619047618|MIOU:0.7770611963793782|IOU:[0.7    0.7692 0.7    0.5    0.625  0.8    0.6667 0.6364 0.8182 1.\n",
      "     0.5385 0.9    0.5833 0.8333 0.9091 1.     1.     0.9    0.9    0.6923\n",
      "     0.7143 0.9091]|ACC:[0.7 1.  0.7 0.5 1.  0.8 0.8 0.7 0.9 1.  0.7 0.9 0.7 1.  1.  1.  1.  0.9\n",
      "     0.9 0.9 1.  1. ]\n",
      "[I 250519 10:30:13 3690967061:135] Iter:74|loss:0.714180052280426\n",
      "[I 250519 10:30:13 3690967061:178] Evaluate 74|OA:0.8727272727272727|MACC:0.8727272727272727|Kappa:0.8666666666666666|MIOU:0.7829522749977297|IOU:[0.7    0.7692 0.7    0.5    0.625  0.8    0.6667 0.6364 0.75   1.\n",
      "     0.6364 0.9    0.6154 0.9091 0.8333 0.9    1.     0.9    0.9    0.7692\n",
      "     0.7143 1.    ]|ACC:[0.7 1.  0.7 0.5 1.  0.8 0.8 0.7 0.9 1.  0.7 0.9 0.8 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:14 3690967061:135] Iter:75|loss:0.6932374238967896\n",
      "[I 250519 10:30:15 3690967061:178] Evaluate 75|OA:0.8727272727272727|MACC:0.8727272727272727|Kappa:0.8666666666666666|MIOU:0.7864880663009006|IOU:[0.7    0.8333 0.7    0.5    0.5882 0.8    0.75   0.5833 0.75   1.\n",
      "     0.5455 0.9    0.5714 0.8333 1.     0.9    1.     0.9    0.9    0.7143\n",
      "     0.8333 1.    ]|ACC:[0.7 1.  0.7 0.5 1.  0.8 0.9 0.7 0.9 1.  0.6 0.9 0.8 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:16 3690967061:135] Iter:76|loss:0.6801307201385498\n",
      "[I 250519 10:30:16 3690967061:178] Evaluate 76|OA:0.8772727272727273|MACC:0.8772727272727271|Kappa:0.8714285714285714|MIOU:0.790685829322193|IOU:[0.7    0.7692 0.7    0.6    0.6667 0.8    0.75   0.6364 0.75   1.\n",
      "     0.5833 0.9    0.5714 0.8333 0.9091 0.9    1.     0.9    0.9    0.6923\n",
      "     0.8333 1.    ]|ACC:[0.7 1.  0.7 0.6 1.  0.8 0.9 0.7 0.9 1.  0.7 0.9 0.8 1.  1.  0.9 1.  0.9\n",
      "     0.9 0.9 1.  1. ]\n",
      "[I 250519 10:30:17 3690967061:135] Iter:77|loss:0.6588026285171509\n",
      "[I 250519 10:30:18 3690967061:178] Evaluate 77|OA:0.8863636363636364|MACC:0.8863636363636362|Kappa:0.8809523809523809|MIOU:0.8045636181999818|IOU:[0.7    0.7692 0.7    0.7    0.7143 0.8    0.75   0.6364 0.75   1.\n",
      "     0.5833 1.     0.5714 0.8333 0.9091 0.9    1.     0.9    0.9    0.75\n",
      "     0.8333 1.    ]|ACC:[0.7 1.  0.7 0.7 1.  0.8 0.9 0.7 0.9 1.  0.7 1.  0.8 1.  1.  0.9 1.  0.9\n",
      "     0.9 0.9 1.  1. ]\n",
      "[I 250519 10:30:19 3690967061:135] Iter:78|loss:0.6467573046684265\n",
      "[I 250519 10:30:19 3690967061:178] Evaluate 78|OA:0.8863636363636364|MACC:0.8863636363636364|Kappa:0.8809523809523809|MIOU:0.8027230345412164|IOU:[0.7    0.7692 0.7    0.6    0.6667 0.8    0.75   0.7273 0.75   1.\n",
      "     0.6364 0.9    0.6154 0.8333 0.9091 0.9    1.     0.9    0.9    0.7692\n",
      "     0.8333 1.    ]|ACC:[0.7 1.  0.7 0.6 1.  0.8 0.9 0.8 0.9 1.  0.7 0.9 0.8 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:20 3690967061:135] Iter:79|loss:0.6269956231117249\n",
      "[I 250519 10:30:21 3690967061:178] Evaluate 79|OA:0.8909090909090909|MACC:0.890909090909091|Kappa:0.8857142857142857|MIOU:0.8110404746768384|IOU:[0.7    0.7692 0.7    0.6    0.6667 0.8    0.75   0.6667 0.75   1.\n",
      "     0.6364 0.9    0.6923 0.8333 1.     0.9    1.     0.9    0.9    0.7692\n",
      "     0.9091 1.    ]|ACC:[0.7 1.  0.7 0.6 1.  0.8 0.9 0.8 0.9 1.  0.7 0.9 0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:21 3690967061:135] Iter:80|loss:0.6150541305541992\n",
      "[I 250519 10:30:22 3690967061:178] Evaluate 80|OA:0.8909090909090909|MACC:0.8909090909090908|Kappa:0.8857142857142857|MIOU:0.8106938516029426|IOU:[0.7    0.7692 0.7    0.7    0.7143 0.8    0.75   0.7273 0.75   1.\n",
      "     0.5833 1.     0.6154 0.8333 0.9091 0.9    1.     0.9    0.9    0.75\n",
      "     0.8333 1.    ]|ACC:[0.7 1.  0.7 0.7 1.  0.8 0.9 0.8 0.9 1.  0.7 1.  0.8 1.  1.  0.9 1.  0.9\n",
      "     0.9 0.9 1.  1. ]\n",
      "[I 250519 10:30:23 3690967061:135] Iter:81|loss:0.597707986831665\n",
      "[I 250519 10:30:23 3690967061:178] Evaluate 81|OA:0.8954545454545455|MACC:0.8954545454545454|Kappa:0.8904761904761905|MIOU:0.8177965973420519|IOU:[0.7    0.7692 0.7    0.7    0.7143 0.8    0.75   0.7273 0.75   1.\n",
      "     0.6364 1.     0.6429 0.75   0.9091 0.9    1.     0.9    0.9    0.8333\n",
      "     0.9091 1.    ]|ACC:[0.7 1.  0.7 0.7 1.  0.8 0.9 0.8 0.9 1.  0.7 1.  0.9 0.9 1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:24 3690967061:135] Iter:82|loss:0.5860605835914612\n",
      "[I 250519 10:30:25 3690967061:178] Evaluate 82|OA:0.9|MACC:0.9|Kappa:0.8952380952380953|MIOU:0.8238322283776829|IOU:[0.7    0.7692 0.7    0.7    0.7143 0.8    0.75   0.7273 0.75   1.\n",
      "     0.6364 1.     0.6923 0.8333 0.9091 0.9    1.     0.9    0.9    0.8333\n",
      "     0.9091 1.    ]|ACC:[0.7 1.  0.7 0.7 1.  0.8 0.9 0.8 0.9 1.  0.7 1.  0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:26 3690967061:135] Iter:83|loss:0.5697703957557678\n",
      "[I 250519 10:30:26 3690967061:178] Evaluate 83|OA:0.9|MACC:0.9|Kappa:0.8952380952380953|MIOU:0.8238322283776829|IOU:[0.7    0.7692 0.7    0.7    0.7143 0.8    0.75   0.7273 0.75   1.\n",
      "     0.6364 1.     0.6923 0.8333 0.9091 0.9    1.     0.9    0.9    0.8333\n",
      "     0.9091 1.    ]|ACC:[0.7 1.  0.7 0.7 1.  0.8 0.9 0.8 0.9 1.  0.7 1.  0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:27 3690967061:135] Iter:84|loss:0.5592530965805054\n",
      "[I 250519 10:30:28 3690967061:178] Evaluate 84|OA:0.9090909090909091|MACC:0.9090909090909091|Kappa:0.9047619047619048|MIOU:0.8383343928798475|IOU:[0.8    0.7692 0.7    0.8    0.8333 0.8    0.75   0.7273 0.75   1.\n",
      "     0.6364 1.     0.6923 0.8333 0.9091 0.9    1.     0.9    0.9    0.8333\n",
      "     0.9091 1.    ]|ACC:[0.8 1.  0.7 0.8 1.  0.8 0.9 0.8 0.9 1.  0.7 1.  0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:29 3690967061:135] Iter:85|loss:0.5445519685745239\n",
      "[I 250519 10:30:29 3690967061:178] Evaluate 85|OA:0.9045454545454545|MACC:0.9045454545454544|Kappa:0.9|MIOU:0.8322987618442164|IOU:[0.8    0.7692 0.7    0.8    0.8333 0.8    0.75   0.7273 0.75   1.\n",
      "     0.6364 1.     0.6429 0.75   0.9091 0.9    1.     0.9    0.9    0.8333\n",
      "     0.9091 1.    ]|ACC:[0.8 1.  0.7 0.8 1.  0.8 0.9 0.8 0.9 1.  0.7 1.  0.9 0.9 1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:30 3690967061:135] Iter:86|loss:0.5340065956115723\n",
      "[I 250519 10:30:31 3690967061:178] Evaluate 86|OA:0.9090909090909091|MACC:0.9090909090909091|Kappa:0.9047619047619048|MIOU:0.8383555838101294|IOU:[0.8    0.8333 0.6364 0.8    0.8333 0.8    0.75   0.7273 0.75   1.\n",
      "     0.6364 1.     0.6923 0.8333 0.9091 0.9    1.     0.9    0.9    0.8333\n",
      "     0.9091 1.    ]|ACC:[0.8 1.  0.7 0.8 1.  0.8 0.9 0.8 0.9 1.  0.7 1.  0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:32 3690967061:135] Iter:87|loss:0.5233648419380188\n",
      "[I 250519 10:30:32 3690967061:178] Evaluate 87|OA:0.9136363636363637|MACC:0.9136363636363636|Kappa:0.9095238095238096|MIOU:0.8455657978385251|IOU:[0.8    0.7692 0.7    0.8    0.8333 0.8    0.8182 0.8182 0.75   1.\n",
      "     0.6364 1.     0.6923 0.8333 0.9091 0.9    1.     0.9    0.9    0.8333\n",
      "     0.9091 1.    ]|ACC:[0.8 1.  0.7 0.8 1.  0.8 0.9 0.9 0.9 1.  0.7 1.  0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:33 3690967061:135] Iter:88|loss:0.5167291164398193\n",
      "[I 250519 10:30:34 3690967061:178] Evaluate 88|OA:0.9090909090909091|MACC:0.909090909090909|Kappa:0.9047619047619048|MIOU:0.8409711500620592|IOU:[0.8    0.7692 0.7    0.8    0.8333 0.8    0.8182 0.7273 0.75   1.\n",
      "     0.6923 1.     0.6429 0.9    0.9091 0.9    1.     0.9    0.9    0.75\n",
      "     0.9091 1.    ]|ACC:[0.8 1.  0.7 0.8 1.  0.8 0.9 0.8 0.9 1.  0.9 1.  0.9 0.9 1.  0.9 1.  0.9\n",
      "     0.9 0.9 1.  1. ]\n",
      "[I 250519 10:30:34 3690967061:135] Iter:89|loss:0.516209065914154\n",
      "[I 250519 10:30:35 3690967061:178] Evaluate 89|OA:0.9136363636363637|MACC:0.9136363636363636|Kappa:0.9095238095238096|MIOU:0.8465299851663488|IOU:[0.8    0.8333 0.6364 0.8    0.8333 0.8    0.8182 0.8182 0.75   1.\n",
      "     0.6364 1.     0.6923 0.7692 0.9091 0.9    1.     0.9    0.8182 0.9091\n",
      "     1.     1.    ]|ACC:[0.8 1.  0.7 0.8 1.  0.8 0.9 0.9 0.9 1.  0.7 1.  0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:36 3690967061:135] Iter:90|loss:0.5221192240715027\n",
      "[I 250519 10:30:36 3690967061:178] Evaluate 90|OA:0.9136363636363637|MACC:0.9136363636363636|Kappa:0.9095238095238096|MIOU:0.8472058244785519|IOU:[0.8    0.8333 0.6364 0.9    0.8333 0.8    0.8182 0.8    0.75   1.\n",
      "     0.6667 1.     0.7143 0.75   0.9091 0.9    1.     0.9    0.9    0.8182\n",
      "     0.9091 1.    ]|ACC:[0.8 1.  0.7 0.9 1.  0.8 0.9 0.8 0.9 1.  0.8 1.  1.  0.9 1.  0.9 1.  0.9\n",
      "     0.9 0.9 1.  1. ]\n",
      "[I 250519 10:30:37 3690967061:135] Iter:91|loss:0.49646228551864624\n",
      "[I 250519 10:30:38 3690967061:178] Evaluate 91|OA:0.9181818181818182|MACC:0.9181818181818181|Kappa:0.9142857142857144|MIOU:0.8546355159991523|IOU:[0.8    0.7692 0.7    0.8    0.8333 0.8    0.9    0.8182 0.75   1.\n",
      "     0.7273 1.     0.6923 0.7692 0.9091 0.9    1.     0.9    0.9    0.8333\n",
      "     1.     1.    ]|ACC:[0.8 1.  0.7 0.8 1.  0.8 0.9 0.9 0.9 1.  0.8 1.  0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:39 3690967061:135] Iter:92|loss:0.47329217195510864\n",
      "[I 250519 10:30:39 3690967061:178] Evaluate 92|OA:0.9136363636363637|MACC:0.9136363636363636|Kappa:0.9095238095238096|MIOU:0.8467842763297309|IOU:[0.8    0.7692 0.7    0.8    0.8333 0.8    0.8182 0.8182 0.75   1.\n",
      "     0.6364 1.     0.6923 0.7692 0.9091 0.9    1.     0.9    0.9    0.8333\n",
      "     1.     1.    ]|ACC:[0.8 1.  0.7 0.8 1.  0.8 0.9 0.9 0.9 1.  0.7 1.  0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:40 3690967061:135] Iter:93|loss:0.476884126663208\n",
      "[I 250519 10:30:41 3690967061:178] Evaluate 93|OA:0.9318181818181818|MACC:0.9318181818181817|Kappa:0.9285714285714285|MIOU:0.8776806526806528|IOU:[0.9    0.8333 0.6364 0.9    0.9091 0.8    0.9    0.8182 0.75   1.\n",
      "     0.8182 1.     0.6923 0.8333 0.9091 0.9    1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[0.9 1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.9 1.  0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:42 3690967061:135] Iter:94|loss:0.4609501361846924\n",
      "[I 250519 10:30:42 3690967061:178] Evaluate 94|OA:0.9272727272727272|MACC:0.9272727272727272|Kappa:0.9238095238095237|MIOU:0.8718561741289015|IOU:[0.9    0.8333 0.6364 0.9    0.9091 0.8    0.9    0.9    0.75   1.\n",
      "     0.7273 1.     0.7143 0.6923 0.9091 0.9    1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[0.9 1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  0.9 1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:43 3690967061:135] Iter:95|loss:0.4468768537044525\n",
      "[I 250519 10:30:44 3690967061:178] Evaluate 95|OA:0.9181818181818182|MACC:0.9181818181818181|Kappa:0.9142857142857144|MIOU:0.8542434837889382|IOU:[0.9    0.8333 0.7    0.8    0.8333 0.8    0.8182 0.8182 0.75   1.\n",
      "     0.6364 1.     0.6923 0.7692 0.9091 0.9    1.     0.9    0.9    0.8333\n",
      "     1.     1.    ]|ACC:[0.9 1.  0.7 0.8 1.  0.8 0.9 0.9 0.9 1.  0.7 1.  0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:44 3690967061:135] Iter:96|loss:0.4444507956504822\n",
      "[I 250519 10:30:45 3690967061:178] Evaluate 96|OA:0.9272727272727272|MACC:0.9272727272727272|Kappa:0.9238095238095237|MIOU:0.8706346683619411|IOU:[0.9    0.8333 0.6364 0.9    0.9091 0.8    0.9    0.8182 0.75   1.\n",
      "     0.7273 1.     0.6923 0.7692 0.9091 0.9    1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[0.9 1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.8 1.  0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:46 3690967061:135] Iter:97|loss:0.42785921692848206\n",
      "[I 250519 10:30:46 3690967061:178] Evaluate 97|OA:0.9363636363636364|MACC:0.9363636363636363|Kappa:0.9333333333333333|MIOU:0.8860487996851635|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.75   1.\n",
      "     0.8182 1.     0.7143 0.75   0.9091 0.9    1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.9 1.  1.  0.9 1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:47 3690967061:135] Iter:98|loss:0.42572641372680664\n",
      "[I 250519 10:30:48 3690967061:178] Evaluate 98|OA:0.9318181818181818|MACC:0.9318181818181817|Kappa:0.9285714285714285|MIOU:0.8780726848908668|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.8182 0.75   1.\n",
      "     0.7273 1.     0.6923 0.7692 0.9091 0.9    1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.8 1.  0.9 1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:49 3690967061:135] Iter:99|loss:0.41400471329689026\n",
      "[I 250519 10:30:49 3690967061:178] Evaluate 99|OA:0.9363636363636364|MACC:0.9363636363636363|Kappa:0.9333333333333333|MIOU:0.8852881966518331|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.75   1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 0.9    1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:50 3690967061:135] Iter:100|loss:0.4050803780555725\n",
      "[I 250519 10:30:51 3690967061:178] Evaluate 100|OA:0.9409090909090909|MACC:0.9409090909090909|Kappa:0.9380952380952381|MIOU:0.8923341809705447|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.75   1.\n",
      "     0.8182 1.     0.7692 0.8333 0.9091 0.9    1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.9 1.  1.  1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:52 3690967061:135] Iter:101|loss:0.39916595816612244\n",
      "[I 250519 10:30:52 3690967061:178] Evaluate 101|OA:0.9454545454545454|MACC:0.9454545454545453|Kappa:0.9428571428571428|MIOU:0.8999788090697183|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.8182 1.\n",
      "     0.8182 1.     0.7692 0.8333 0.9091 1.     1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.9 1.  1.  1.  1.  1.  1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:53 3690967061:135] Iter:102|loss:0.3875802159309387\n",
      "[I 250519 10:30:54 3690967061:178] Evaluate 102|OA:0.9363636363636364|MACC:0.9363636363636363|Kappa:0.9333333333333333|MIOU:0.8852881966518331|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.75   1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 0.9    1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:54 3690967061:135] Iter:103|loss:0.3852322995662689\n",
      "[I 250519 10:30:55 3690967061:178] Evaluate 103|OA:0.9363636363636364|MACC:0.9363636363636363|Kappa:0.9333333333333333|MIOU:0.8852881966518331|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.75   1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 0.9    1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:56 3690967061:135] Iter:104|loss:0.37315425276756287\n",
      "[I 250519 10:30:56 3690967061:178] Evaluate 104|OA:0.9454545454545454|MACC:0.9454545454545453|Kappa:0.9428571428571428|MIOU:0.8999788090697183|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.8182 1.\n",
      "     0.8182 1.     0.7692 0.8333 0.9091 1.     1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.9 1.  1.  1.  1.  1.  1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:57 3690967061:135] Iter:105|loss:0.3702302575111389\n",
      "[I 250519 10:30:58 3690967061:178] Evaluate 105|OA:0.9409090909090909|MACC:0.9409090909090907|Kappa:0.9380952380952381|MIOU:0.8929328247510067|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.8182 1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 1.     1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  1.  1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:30:59 3690967061:135] Iter:106|loss:0.359519898891449\n",
      "[I 250519 10:30:59 3690967061:178] Evaluate 106|OA:0.9409090909090909|MACC:0.9409090909090907|Kappa:0.9380952380952381|MIOU:0.8929328247510067|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.8182 1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 1.     1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  1.  1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:00 3690967061:135] Iter:107|loss:0.3553261160850525\n",
      "[I 250519 10:31:01 3690967061:178] Evaluate 107|OA:0.9363636363636364|MACC:0.9363636363636363|Kappa:0.9333333333333333|MIOU:0.8852881966518331|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.75   1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 0.9    1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  0.9 1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:02 3690967061:135] Iter:108|loss:0.34760987758636475\n",
      "[I 250519 10:31:02 3690967061:178] Evaluate 108|OA:0.9454545454545454|MACC:0.9454545454545453|Kappa:0.9428571428571428|MIOU:0.8999788090697183|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.8182 1.\n",
      "     0.8182 1.     0.7692 0.8333 0.9091 1.     1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.9 1.  1.  1.  1.  1.  1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:03 3690967061:135] Iter:109|loss:0.34175679087638855\n",
      "[I 250519 10:31:04 3690967061:178] Evaluate 109|OA:0.9409090909090909|MACC:0.9409090909090907|Kappa:0.9380952380952381|MIOU:0.8929328247510067|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.8182 1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 1.     1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  1.  1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:04 3690967061:135] Iter:110|loss:0.33599579334259033\n",
      "[I 250519 10:31:05 3690967061:178] Evaluate 110|OA:0.9409090909090909|MACC:0.9409090909090907|Kappa:0.9380952380952381|MIOU:0.8929328247510067|IOU:[1.     0.8333 0.7    0.9    0.9091 0.8    0.9    0.9    0.8182 1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 1.     1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 0.9 1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  1.  1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:06 3690967061:135] Iter:111|loss:0.3290032148361206\n",
      "[I 250519 10:31:06 3690967061:178] Evaluate 111|OA:0.9545454545454546|MACC:0.9545454545454546|Kappa:0.9523809523809524|MIOU:0.9169209578300488|IOU:[1.     0.8333 0.7    1.     1.     0.8    0.9    0.9    0.9    1.\n",
      "     0.8182 1.     0.7692 0.8333 0.9091 1.     1.     1.     0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.8 0.9 0.9 0.9 1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:07 3690967061:135] Iter:112|loss:0.32409289479255676\n",
      "[I 250519 10:31:08 3690967061:178] Evaluate 112|OA:0.95|MACC:0.95|Kappa:0.9476190476190476|MIOU:0.9098749735113372|IOU:[1.     0.8333 0.7    1.     1.     0.8    0.9    0.9    0.9    1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 1.     1.     1.     0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:09 3690967061:135] Iter:113|loss:0.3169298470020294\n",
      "[I 250519 10:31:09 3690967061:178] Evaluate 113|OA:0.9454545454545454|MACC:0.9454545454545453|Kappa:0.9428571428571428|MIOU:0.9016105107014197|IOU:[1.     0.8333 0.7    1.     1.     0.8    0.9    0.9    0.8182 1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 1.     1.     0.9    0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  1.  1.  0.9\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:10 3690967061:135] Iter:114|loss:0.3122432231903076\n",
      "[I 250519 10:31:11 3690967061:178] Evaluate 114|OA:0.95|MACC:0.95|Kappa:0.9476190476190476|MIOU:0.9098749735113372|IOU:[1.     0.8333 0.7    1.     1.     0.8    0.9    0.9    0.9    1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 1.     1.     1.     0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:11 3690967061:135] Iter:115|loss:0.3057112395763397\n",
      "[I 250519 10:31:12 3690967061:178] Evaluate 115|OA:0.9590909090909091|MACC:0.959090909090909|Kappa:0.9571428571428572|MIOU:0.925185420639966|IOU:[1.     0.8333 0.7    1.     1.     0.8    0.9    0.9    0.9    1.\n",
      "     0.9091 1.     0.7692 0.8333 0.9091 1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.8 0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:13 3690967061:135] Iter:116|loss:0.30117082595825195\n",
      "[I 250519 10:31:13 3690967061:178] Evaluate 116|OA:0.95|MACC:0.95|Kappa:0.9476190476190476|MIOU:0.9098749735113372|IOU:[1.     0.8333 0.7    1.     1.     0.8    0.9    0.9    0.9    1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 1.     1.     1.     0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:14 3690967061:135] Iter:117|loss:0.2952553629875183\n",
      "[I 250519 10:31:15 3690967061:178] Evaluate 117|OA:0.95|MACC:0.95|Kappa:0.9476190476190476|MIOU:0.9098749735113372|IOU:[1.     0.8333 0.7    1.     1.     0.8    0.9    0.9    0.9    1.\n",
      "     0.7273 1.     0.7692 0.7692 0.9091 1.     1.     1.     0.9    0.9091\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.8 0.9 0.9 0.9 1.  0.8 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:16 3690967061:135] Iter:118|loss:0.2907536029815674\n",
      "[I 250519 10:31:16 3690967061:178] Evaluate 118|OA:0.9590909090909091|MACC:0.959090909090909|Kappa:0.9571428571428572|MIOU:0.9264038991311718|IOU:[1.     0.8333 0.7    1.     1.     0.8    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.7692 0.7692 0.9091 1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.8 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:17 3690967061:135] Iter:119|loss:0.2853713631629944\n",
      "[I 250519 10:31:18 3690967061:178] Evaluate 119|OA:0.9590909090909091|MACC:0.959090909090909|Kappa:0.9571428571428572|MIOU:0.9264038991311718|IOU:[1.     0.8333 0.7    1.     1.     0.8    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.7692 0.7692 0.9091 1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.8 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:19 3690967061:135] Iter:120|loss:0.28082218766212463\n",
      "[I 250519 10:31:19 3690967061:178] Evaluate 120|OA:0.9590909090909091|MACC:0.959090909090909|Kappa:0.9571428571428572|MIOU:0.9264038991311718|IOU:[1.     0.8333 0.7    1.     1.     0.8    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.7692 0.7692 0.9091 1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.8 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:20 3690967061:135] Iter:121|loss:0.27609965205192566\n",
      "[I 250519 10:31:21 3690967061:178] Evaluate 121|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.9338631065903793|IOU:[1.     0.8333 0.7    1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.7692 0.9091 1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:21 3690967061:135] Iter:122|loss:0.2714988589286804\n",
      "[I 250519 10:31:22 3690967061:178] Evaluate 122|OA:0.9590909090909091|MACC:0.959090909090909|Kappa:0.9571428571428572|MIOU:0.9264038991311718|IOU:[1.     0.8333 0.7    1.     1.     0.8    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.7692 0.7692 0.9091 1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.8 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:23 3690967061:135] Iter:123|loss:0.26730915904045105\n",
      "[I 250519 10:31:24 3690967061:178] Evaluate 123|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.9338631065903793|IOU:[1.     0.8333 0.7    1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.7692 0.9091 1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:24 3690967061:135] Iter:124|loss:0.26297256350517273\n",
      "[I 250519 10:31:25 3690967061:178] Evaluate 124|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.9338631065903793|IOU:[1.     0.8333 0.7    1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.7692 0.9091 1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:26 3690967061:135] Iter:125|loss:0.2594098746776581\n",
      "[I 250519 10:31:26 3690967061:178] Evaluate 125|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9413223140495867|IOU:[1.     0.8333 0.7    1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     1.     1.     0.8333 0.8333 0.9091 1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:27 3690967061:135] Iter:126|loss:0.2564292252063751\n",
      "[I 250519 10:31:28 3690967061:178] Evaluate 126|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.9351027760118669|IOU:[1.     0.8333 0.6364 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.7692 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:29 3690967061:135] Iter:127|loss:0.25599274039268494\n",
      "[I 250519 10:31:29 3690967061:178] Evaluate 127|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.8    1.     1.     0.9    0.8182 0.8182 1.     1.\n",
      "     0.9    1.     0.8333 1.     0.9091 1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:30 3690967061:135] Iter:128|loss:0.2585242986679077\n",
      "[I 250519 10:31:31 3690967061:178] Evaluate 128|OA:0.9590909090909091|MACC:0.9590909090909091|Kappa:0.9571428571428572|MIOU:0.9243801652892562|IOU:[1.     0.8333 0.7    1.     1.     0.9    0.9    0.9    0.9    0.9091\n",
      "     0.8182 1.     0.8333 0.8333 1.     0.9    0.9091 1.     1.     1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 0.9 1.  0.9 1.  1.  1.  1.  0.9 1.  1.\n",
      "     1.  1.  1.  1. ]\n",
      "[I 250519 10:31:31 3690967061:135] Iter:129|loss:0.27340537309646606\n",
      "[I 250519 10:31:32 3690967061:178] Evaluate 129|OA:0.9636363636363636|MACC:0.9636363636363636|Kappa:0.9619047619047619|MIOU:0.9350497986861622|IOU:[1.     0.8333 0.8    1.     1.     0.9    0.8182 0.6923 1.     1.\n",
      "     0.9    1.     0.8182 1.     0.9091 1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  0.9 1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:33 3690967061:135] Iter:130|loss:0.27067646384239197\n",
      "[I 250519 10:31:33 3690967061:178] Evaluate 130|OA:0.9590909090909091|MACC:0.959090909090909|Kappa:0.9571428571428572|MIOU:0.9276435685526594|IOU:[1.     0.8333 0.6364 1.     1.     0.8    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.7692 0.7692 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.8 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:34 3690967061:135] Iter:131|loss:0.2543114423751831\n",
      "[I 250519 10:31:35 3690967061:178] Evaluate 131|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:36 3690967061:135] Iter:132|loss:0.2373453825712204\n",
      "[I 250519 10:31:36 3690967061:178] Evaluate 132|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.9327823691460054|IOU:[1.     0.8333 0.7    1.     1.     0.9    0.8182 0.8182 1.     1.\n",
      "     0.9    1.     0.8333 1.     0.9091 1.     1.     1.     0.9    1.\n",
      "     0.9091 1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:37 3690967061:135] Iter:133|loss:0.24546420574188232\n",
      "[I 250519 10:31:38 3690967061:178] Evaluate 133|OA:0.9590909090909091|MACC:0.959090909090909|Kappa:0.9571428571428572|MIOU:0.9264250900614536|IOU:[1.     0.8333 0.6364 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     0.9    1.     0.8333 0.7692 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:39 3690967061:135] Iter:134|loss:0.2334161400794983\n",
      "[I 250519 10:31:39 3690967061:178] Evaluate 134|OA:0.9590909090909091|MACC:0.959090909090909|Kappa:0.9571428571428572|MIOU:0.9268383132019494|IOU:[1.     0.8333 0.6364 1.     1.     0.9    0.9    0.9    0.9    1.\n",
      "     0.8182 1.     0.8333 0.7692 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 0.9 1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:40 3690967061:135] Iter:135|loss:0.23082883656024933\n",
      "[I 250519 10:31:41 3690967061:178] Evaluate 135|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.9326446280991736|IOU:[1.     0.8333 0.7    1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 0.9091 1.     1.     1.     0.9    1.\n",
      "     0.9091 1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:41 3690967061:135] Iter:136|loss:0.2280333787202835\n",
      "[I 250519 10:31:42 3690967061:178] Evaluate 136|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.933884297520661|IOU:[1.     0.8333 0.6364 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     0.9091 1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:43 3690967061:135] Iter:137|loss:0.21964749693870544\n",
      "[I 250519 10:31:43 3690967061:178] Evaluate 137|OA:0.9590909090909091|MACC:0.959090909090909|Kappa:0.9571428571428572|MIOU:0.9264250900614536|IOU:[1.     0.8333 0.6364 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     0.9    1.     0.8333 0.7692 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:44 3690967061:135] Iter:138|loss:0.22193987667560577\n",
      "[I 250519 10:31:45 3690967061:178] Evaluate 138|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.9351027760118669|IOU:[1.     0.8333 0.6364 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.7692 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:46 3690967061:135] Iter:139|loss:0.21224869787693024\n",
      "[I 250519 10:31:46 3690967061:178] Evaluate 139|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.933884297520661|IOU:[1.     0.8333 0.6364 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     0.9091 1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:47 3690967061:135] Iter:140|loss:0.21475055813789368\n",
      "[I 250519 10:31:48 3690967061:178] Evaluate 140|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.9351027760118669|IOU:[1.     0.8333 0.6364 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.7692 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:49 3690967061:135] Iter:141|loss:0.20746926963329315\n",
      "[I 250519 10:31:49 3690967061:178] Evaluate 141|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.9351027760118669|IOU:[1.     0.8333 0.6364 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.7692 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:50 3690967061:135] Iter:142|loss:0.20682090520858765\n",
      "[I 250519 10:31:51 3690967061:178] Evaluate 142|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.9351027760118669|IOU:[1.     0.8333 0.6364 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.7692 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:51 3690967061:135] Iter:143|loss:0.2018294334411621\n",
      "[I 250519 10:31:52 3690967061:178] Evaluate 143|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9418732782369147|IOU:[1.     0.8333 0.6364 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     1.     1.     0.8333 0.9091 1.     1.     1.     1.     0.9    1.\n",
      "     0.9091 1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:53 3690967061:135] Iter:144|loss:0.2003951519727707\n",
      "[I 250519 10:31:53 3690967061:178] Evaluate 144|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:54 3690967061:135] Iter:145|loss:0.19622421264648438\n",
      "[I 250519 10:31:55 3690967061:178] Evaluate 145|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:56 3690967061:135] Iter:146|loss:0.19421802461147308\n",
      "[I 250519 10:31:56 3690967061:178] Evaluate 146|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:57 3690967061:135] Iter:147|loss:0.19129358232021332\n",
      "[I 250519 10:31:58 3690967061:178] Evaluate 147|OA:0.9636363636363636|MACC:0.9636363636363634|Kappa:0.9619047619047619|MIOU:0.933884297520661|IOU:[1.     0.8333 0.6364 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     0.9091 1.    ]|ACC:[1.  1.  0.7 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:31:59 3690967061:135] Iter:148|loss:0.18840257823467255\n",
      "[I 250519 10:31:59 3690967061:178] Evaluate 148|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:00 3690967061:135] Iter:149|loss:0.18616704642772675\n",
      "[I 250519 10:32:01 3690967061:178] Evaluate 149|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:02 3690967061:135] Iter:150|loss:0.18321774899959564\n",
      "[I 250519 10:32:02 3690967061:178] Evaluate 150|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:03 3690967061:135] Iter:151|loss:0.18093322217464447\n",
      "[I 250519 10:32:03 3690967061:178] Evaluate 151|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:04 3690967061:135] Iter:152|loss:0.17817693948745728\n",
      "[I 250519 10:32:05 3690967061:178] Evaluate 152|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:06 3690967061:135] Iter:153|loss:0.1762830913066864\n",
      "[I 250519 10:32:06 3690967061:178] Evaluate 153|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:07 3690967061:135] Iter:154|loss:0.17324477434158325\n",
      "[I 250519 10:32:08 3690967061:178] Evaluate 154|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:09 3690967061:135] Iter:155|loss:0.17167316377162933\n",
      "[I 250519 10:32:09 3690967061:178] Evaluate 155|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:10 3690967061:135] Iter:156|loss:0.16877885162830353\n",
      "[I 250519 10:32:11 3690967061:178] Evaluate 156|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:11 3690967061:135] Iter:157|loss:0.16698205471038818\n",
      "[I 250519 10:32:12 3690967061:178] Evaluate 157|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:13 3690967061:135] Iter:158|loss:0.16436390578746796\n",
      "[I 250519 10:32:13 3690967061:178] Evaluate 158|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:14 3690967061:135] Iter:159|loss:0.16271167993545532\n",
      "[I 250519 10:32:15 3690967061:178] Evaluate 159|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:16 3690967061:135] Iter:160|loss:0.16002435982227325\n",
      "[I 250519 10:32:16 3690967061:178] Evaluate 160|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:17 3690967061:135] Iter:161|loss:0.15848100185394287\n",
      "[I 250519 10:32:18 3690967061:178] Evaluate 161|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:19 3690967061:135] Iter:162|loss:0.15597593784332275\n",
      "[I 250519 10:32:19 3690967061:178] Evaluate 162|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:20 3690967061:135] Iter:163|loss:0.15428045392036438\n",
      "[I 250519 10:32:21 3690967061:178] Evaluate 163|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:21 3690967061:135] Iter:164|loss:0.15205517411231995\n",
      "[I 250519 10:32:22 3690967061:178] Evaluate 164|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:23 3690967061:135] Iter:165|loss:0.15031124651432037\n",
      "[I 250519 10:32:23 3690967061:178] Evaluate 165|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:24 3690967061:135] Iter:166|loss:0.14815106987953186\n",
      "[I 250519 10:32:25 3690967061:178] Evaluate 166|OA:0.9727272727272728|MACC:0.9727272727272727|Kappa:0.9714285714285715|MIOU:0.9501377410468319|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     1.     1.     0.8333 0.9091 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:26 3690967061:135] Iter:167|loss:0.14642676711082458\n",
      "[I 250519 10:32:26 3690967061:178] Evaluate 167|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:27 3690967061:135] Iter:168|loss:0.14443452656269073\n",
      "[I 250519 10:32:28 3690967061:178] Evaluate 168|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:29 3690967061:135] Iter:169|loss:0.1426386684179306\n",
      "[I 250519 10:32:29 3690967061:178] Evaluate 169|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9421487603305785|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     0.9    1.     0.8333 0.8333 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:30 3690967061:135] Iter:170|loss:0.14079147577285767\n",
      "[I 250519 10:32:31 3690967061:178] Evaluate 170|OA:0.9727272727272728|MACC:0.9727272727272727|Kappa:0.9714285714285715|MIOU:0.9501377410468319|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     1.     1.     0.8333 0.9091 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:31 3690967061:135] Iter:171|loss:0.13897275924682617\n",
      "[I 250519 10:32:32 3690967061:178] Evaluate 171|OA:0.9636363636363636|MACC:0.9636363636363636|Kappa:0.9619047619047619|MIOU:0.9334710743801652|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     0.9    1.     0.8333 0.8333 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:33 3690967061:135] Iter:172|loss:0.1372077316045761\n",
      "[I 250519 10:32:33 3690967061:178] Evaluate 172|OA:0.9636363636363636|MACC:0.9636363636363636|Kappa:0.9619047619047619|MIOU:0.9334710743801652|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     0.9    1.     0.8333 0.8333 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:34 3690967061:135] Iter:173|loss:0.13543161749839783\n",
      "[I 250519 10:32:35 3690967061:178] Evaluate 173|OA:0.9727272727272728|MACC:0.9727272727272727|Kappa:0.9714285714285715|MIOU:0.9501377410468319|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     1.     1.     0.8333 0.9091 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:36 3690967061:135] Iter:174|loss:0.1337442398071289\n",
      "[I 250519 10:32:36 3690967061:178] Evaluate 174|OA:0.9727272727272728|MACC:0.9727272727272727|Kappa:0.9714285714285715|MIOU:0.9501377410468319|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     1.     1.     0.8333 0.9091 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:37 3690967061:135] Iter:175|loss:0.1319453865289688\n",
      "[I 250519 10:32:38 3690967061:178] Evaluate 175|OA:0.9636363636363636|MACC:0.9636363636363636|Kappa:0.9619047619047619|MIOU:0.9334710743801652|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     0.9    1.     0.8333 0.8333 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:39 3690967061:135] Iter:176|loss:0.13033543527126312\n",
      "[I 250519 10:32:39 3690967061:178] Evaluate 176|OA:0.9636363636363636|MACC:0.9636363636363636|Kappa:0.9619047619047619|MIOU:0.9334710743801652|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     0.9    1.     0.8333 0.8333 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:40 3690967061:135] Iter:177|loss:0.12858447432518005\n",
      "[I 250519 10:32:41 3690967061:178] Evaluate 177|OA:0.9727272727272728|MACC:0.9727272727272727|Kappa:0.9714285714285715|MIOU:0.9501377410468319|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    1.     1.\n",
      "     1.     1.     0.8333 0.9091 1.     1.     1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:41 3690967061:135] Iter:178|loss:0.1269882172346115\n",
      "[I 250519 10:32:42 3690967061:178] Evaluate 178|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:43 3690967061:135] Iter:179|loss:0.12531478703022003\n",
      "[I 250519 10:32:43 3690967061:178] Evaluate 179|OA:0.9636363636363636|MACC:0.9636363636363636|Kappa:0.9619047619047619|MIOU:0.9334710743801652|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     0.9    1.     0.8333 0.8333 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:44 3690967061:135] Iter:180|loss:0.12372668087482452\n",
      "[I 250519 10:32:45 3690967061:178] Evaluate 180|OA:0.9636363636363636|MACC:0.9636363636363636|Kappa:0.9619047619047619|MIOU:0.9334710743801652|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     0.9    1.     0.8333 0.8333 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  0.9 1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:46 3690967061:135] Iter:181|loss:0.12212212383747101\n",
      "[I 250519 10:32:46 3690967061:178] Evaluate 181|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:47 3690967061:135] Iter:182|loss:0.12055890262126923\n",
      "[I 250519 10:32:48 3690967061:178] Evaluate 182|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:49 3690967061:135] Iter:183|loss:0.11900358647108078\n",
      "[I 250519 10:32:49 3690967061:178] Evaluate 183|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:50 3690967061:135] Iter:184|loss:0.11746509373188019\n",
      "[I 250519 10:32:51 3690967061:178] Evaluate 184|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:51 3690967061:135] Iter:185|loss:0.1159612163901329\n",
      "[I 250519 10:32:52 3690967061:178] Evaluate 185|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:53 3690967061:135] Iter:186|loss:0.11444026231765747\n",
      "[I 250519 10:32:53 3690967061:178] Evaluate 186|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:54 3690967061:135] Iter:187|loss:0.11296932399272919\n",
      "[I 250519 10:32:55 3690967061:178] Evaluate 187|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:56 3690967061:135] Iter:188|loss:0.11150557547807693\n",
      "[I 250519 10:32:56 3690967061:178] Evaluate 188|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:57 3690967061:135] Iter:189|loss:0.11005479097366333\n",
      "[I 250519 10:32:58 3690967061:178] Evaluate 189|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:32:59 3690967061:135] Iter:190|loss:0.10864076018333435\n",
      "[I 250519 10:32:59 3690967061:178] Evaluate 190|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:33:00 3690967061:135] Iter:191|loss:0.10721728950738907\n",
      "[I 250519 10:33:01 3690967061:178] Evaluate 191|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:33:01 3690967061:135] Iter:192|loss:0.10583556443452835\n",
      "[I 250519 10:33:02 3690967061:178] Evaluate 192|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:33:03 3690967061:135] Iter:193|loss:0.10443660616874695\n",
      "[I 250519 10:33:03 3690967061:178] Evaluate 193|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:33:04 3690967061:135] Iter:194|loss:0.10309363901615143\n",
      "[I 250519 10:33:05 3690967061:178] Evaluate 194|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:33:06 3690967061:135] Iter:195|loss:0.10173795372247696\n",
      "[I 250519 10:33:06 3690967061:178] Evaluate 195|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:33:07 3690967061:135] Iter:196|loss:0.10040459036827087\n",
      "[I 250519 10:33:08 3690967061:178] Evaluate 196|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:33:09 3690967061:135] Iter:197|loss:0.09910265356302261\n",
      "[I 250519 10:33:09 3690967061:178] Evaluate 197|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:33:10 3690967061:135] Iter:198|loss:0.09778697043657303\n",
      "[I 250519 10:33:11 3690967061:178] Evaluate 198|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:33:11 3690967061:135] Iter:199|loss:0.09651588648557663\n",
      "[I 250519 10:33:12 3690967061:178] Evaluate 199|OA:0.9681818181818181|MACC:0.968181818181818|Kappa:0.9666666666666667|MIOU:0.9414600550964187|IOU:[1.     0.8333 0.7273 1.     1.     0.9    0.9    0.9    0.9091 1.\n",
      "     1.     1.     0.8333 0.9091 1.     0.9    1.     1.     0.9    1.\n",
      "     1.     1.    ]|ACC:[1.  1.  0.8 1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  0.9 1.  1.\n",
      "     0.9 1.  1.  1. ]\n",
      "[I 250519 10:33:12 3690967061:190] \n",
      "    \n",
      "    ====================Starting evaluation for testing set.========================\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "量化模型转化\n",
      "量化模型转化成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 250519 10:33:12 3690967061:226] Test 199|OA:0.9623418599165917|MACC:0.9653295118910371|Kappa:0.9666666666666667|MIOU:0.8648830892565026|IOU:[0.943  0.6439 0.8786 0.9864 0.8854 0.952  0.8164 0.923  0.9422 0.9327\n",
      "     0.8583 0.8353 0.8642 0.8422 0.6024 0.9559 0.9528 0.7848 0.9079 0.9429\n",
      "     0.6862 0.8907]|ACC:[0.9603 0.9859 0.9009 0.9898 0.9956 0.9569 0.8318 0.9562 0.9897 0.946\n",
      "     0.9195 0.9762 0.9422 0.987  1.     0.967  0.9865 0.9909 0.9623 0.9925\n",
      "     1.     1.    ]\n",
      "[I 250519 10:33:12 3690967061:248] \n",
      "    ====================== exp_idx=0 seed=0 learning rate=0.0003 epochs=200 train ratio=0.1 val ratio=0.01 ======================\n",
      "    OA=0.9623418599165917\n",
      "    AA=0.9653295118910371\n",
      "    kpp=0.9666666666666667\n",
      "    mIOU_test:0.8648830892565026\n",
      "    IOU_test:[0.943  0.6439 0.8786 0.9864 0.8854 0.952  0.8164 0.923  0.9422 0.9327\n",
      "     0.8583 0.8353 0.8642 0.8422 0.6024 0.9559 0.9528 0.7848 0.9079 0.9429\n",
      "     0.6862 0.8907]\n",
      "    Acc_test:[0.9603 0.9859 0.9009 0.9898 0.9956 0.9569 0.8318 0.9562 0.9897 0.946\n",
      "     0.9195 0.9762 0.9422 0.987  1.     0.967  0.9865 0.9909 0.9623 0.9925\n",
      "     1.     1.    ]\n",
      "    \n",
      "[I 250519 10:33:13 3690967061:269] \n",
      "    ====================Mean result of 1 times runs =========================\n",
      "[I 250519 10:33:13 3690967061:270] Bad message (TypeError('not all arguments converted during string formatting')): {'name': 'HongHu', 'msg': 'List of OA:', 'args': ([np.float64(0.9623418599165917)],), 'levelname': 'INFO', 'levelno': 20, 'pathname': '/tmp/ipykernel_55240/3690967061.py', 'filename': '3690967061.py', 'module': '3690967061', 'exc_info': None, 'exc_text': None, 'stack_info': None, 'lineno': 270, 'funcName': '<module>', 'created': 1747650793.012135, 'msecs': 12.0, 'relativeCreated': 763002.7749538422, 'thread': 140650373833664, 'threadName': 'MainThread', 'processName': 'MainProcess', 'process': 55240}\n",
      "[I 250519 10:33:13 3690967061:271] Bad message (TypeError('not all arguments converted during string formatting')): {'name': 'HongHu', 'msg': 'List of AA:', 'args': ([np.float64(0.9653295118910371)],), 'levelname': 'INFO', 'levelno': 20, 'pathname': '/tmp/ipykernel_55240/3690967061.py', 'filename': '3690967061.py', 'module': '3690967061', 'exc_info': None, 'exc_text': None, 'stack_info': None, 'lineno': 271, 'funcName': '<module>', 'created': 1747650793.0143495, 'msecs': 14.0, 'relativeCreated': 763004.9893856049, 'thread': 140650373833664, 'threadName': 'MainThread', 'processName': 'MainProcess', 'process': 55240}\n",
      "[I 250519 10:33:13 3690967061:272] Bad message (TypeError('not all arguments converted during string formatting')): {'name': 'HongHu', 'msg': 'List of KPP:', 'args': ([np.float64(0.9666666666666667)],), 'levelname': 'INFO', 'levelno': 20, 'pathname': '/tmp/ipykernel_55240/3690967061.py', 'filename': '3690967061.py', 'module': '3690967061', 'exc_info': None, 'exc_text': None, 'stack_info': None, 'lineno': 272, 'funcName': '<module>', 'created': 1747650793.0158553, 'msecs': 15.0, 'relativeCreated': 763006.4952373505, 'thread': 140650373833664, 'threadName': 'MainThread', 'processName': 'MainProcess', 'process': 55240}\n",
      "[I 250519 10:33:13 3690967061:273] Bad message (TypeError('not all arguments converted during string formatting')): {'name': 'HongHu', 'msg': 'OA=', 'args': (np.float64(96.23), '+-', np.float64(0.0)), 'levelname': 'INFO', 'levelno': 20, 'pathname': '/tmp/ipykernel_55240/3690967061.py', 'filename': '3690967061.py', 'module': '3690967061', 'exc_info': None, 'exc_text': None, 'stack_info': None, 'lineno': 273, 'funcName': '<module>', 'created': 1747650793.0183175, 'msecs': 18.0, 'relativeCreated': 763008.9573860168, 'thread': 140650373833664, 'threadName': 'MainThread', 'processName': 'MainProcess', 'process': 55240}\n",
      "[I 250519 10:33:13 3690967061:274] Bad message (TypeError('not all arguments converted during string formatting')): {'name': 'HongHu', 'msg': 'AA=', 'args': (np.float64(96.53), '+-', np.float64(0.0)), 'levelname': 'INFO', 'levelno': 20, 'pathname': '/tmp/ipykernel_55240/3690967061.py', 'filename': '3690967061.py', 'module': '3690967061', 'exc_info': None, 'exc_text': None, 'stack_info': None, 'lineno': 274, 'funcName': '<module>', 'created': 1747650793.0193043, 'msecs': 19.0, 'relativeCreated': 763009.9442005157, 'thread': 140650373833664, 'threadName': 'MainThread', 'processName': 'MainProcess', 'process': 55240}\n",
      "[I 250519 10:33:13 3690967061:275] Bad message (TypeError('not all arguments converted during string formatting')): {'name': 'HongHu', 'msg': 'Kpp=', 'args': (np.float64(96.67), '+-', np.float64(0.0)), 'levelname': 'INFO', 'levelno': 20, 'pathname': '/tmp/ipykernel_55240/3690967061.py', 'filename': '3690967061.py', 'module': '3690967061', 'exc_info': None, 'exc_text': None, 'stack_info': None, 'lineno': 275, 'funcName': '<module>', 'created': 1747650793.0202835, 'msecs': 20.0, 'relativeCreated': 763010.9233856201, 'thread': 140650373833664, 'threadName': 'MainThread', 'processName': 'MainProcess', 'process': 55240}\n",
      "[I 250519 10:33:13 3690967061:276] Bad message (TypeError('not all arguments converted during string formatting')): {'name': 'HongHu', 'msg': 'Acc per class=', 'args': (array([ 96.03,  98.59,  90.09,  98.98,  99.56,  95.69,  83.18,  95.62,\n",
      "            98.97,  94.6 ,  91.95,  97.62,  94.22,  98.7 , 100.  ,  96.7 ,\n",
      "            98.65,  99.09,  96.23,  99.25, 100.  , 100.  ]), '+-', array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "           0., 0., 0., 0., 0.])), 'levelname': 'INFO', 'levelno': 20, 'pathname': '/tmp/ipykernel_55240/3690967061.py', 'filename': '3690967061.py', 'module': '3690967061', 'exc_info': None, 'exc_text': None, 'stack_info': None, 'lineno': 276, 'funcName': '<module>', 'created': 1747650793.0211413, 'msecs': 21.0, 'relativeCreated': 763011.7812156677, 'thread': 140650373833664, 'threadName': 'MainThread', 'processName': 'MainProcess', 'process': 55240}\n",
      "[I 250519 10:33:13 3690967061:279] Bad message (TypeError('not all arguments converted during string formatting')): {'name': 'HongHu', 'msg': 'Average training time=', 'args': (np.float64(nan), '+-', np.float64(nan)), 'levelname': 'INFO', 'levelno': 20, 'pathname': '/tmp/ipykernel_55240/3690967061.py', 'filename': '3690967061.py', 'module': '3690967061', 'exc_info': None, 'exc_text': None, 'stack_info': None, 'lineno': 279, 'funcName': '<module>', 'created': 1747650793.0230293, 'msecs': 23.0, 'relativeCreated': 763013.6692523956, 'thread': 140650373833664, 'threadName': 'MainThread', 'processName': 'MainProcess', 'process': 55240}\n",
      "[I 250519 10:33:13 3690967061:280] Bad message (TypeError('not all arguments converted during string formatting')): {'name': 'HongHu', 'msg': 'Average testing time=', 'args': (np.float64(214.93), '+-', np.float64(0.0)), 'levelname': 'INFO', 'levelno': 20, 'pathname': '/tmp/ipykernel_55240/3690967061.py', 'filename': '3690967061.py', 'module': '3690967061', 'exc_info': None, 'exc_text': None, 'stack_info': None, 'lineno': 280, 'funcName': '<module>', 'created': 1747650793.0238566, 'msecs': 23.0, 'relativeCreated': 763014.4965648651, 'thread': 140650373833664, 'threadName': 'MainThread', 'processName': 'MainProcess', 'process': 55240}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21492600440979004\n"
     ]
    }
   ],
   "source": [
    "save_folder = os.path.join(work_dir, exp_name, net_name, data_set_name)\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    print(\"makedirs {}\".format(save_folder))\n",
    "    \n",
    "save_log_path = os.path.join(save_folder,'train_tr{}_val{}.log'.format(num_list[0],num_list[1]))\n",
    "# 创建与数据集同名的日志记录器，并指定日志文件路径\n",
    "logger = setup_logger(\n",
    "    name='{}'.format(data_set_name),  # 日志器名称 = 数据集名称\n",
    "    logfile=save_log_path            # 日志文件保存路径\n",
    ")\n",
    "torch.cuda.empty_cache()#手动释放 GPU 未使用缓存内存 的函数\n",
    "logger.info(save_folder)\n",
    "\n",
    "data_set_path = args.data_set_path\n",
    "data, gt = data_load_operate.load_data(data_set_name, data_set_path)\n",
    "gt_reshape = gt.reshape(-1)\n",
    "height, width, channels = data.shape\n",
    "img = ImageStretching(data)#将每个通道的数据变成0-255\n",
    "class_count = max(np.unique(gt))\n",
    "ratio_list = [0.1, 0.01]\n",
    "flag_list = [1, 0]\n",
    "\n",
    "OA_ALL = []\n",
    "AA_ALL = []\n",
    "KPP_ALL = []\n",
    "EACH_ACC_ALL = []\n",
    "Train_Time_ALL = []\n",
    "Test_Time_ALL = []\n",
    "CLASS_ACC = np.zeros([len(seed_list), class_count])\n",
    "evaluator = Evaluator(num_class=class_count)\n",
    "loss_func = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "for exp_idx,curr_seed in enumerate(seed_list):\n",
    "    setup_seed(curr_seed)\n",
    "    single_experiment_name = 'run{}_seed{}'.format(str(exp_idx), str(curr_seed))\n",
    "    save_single_experiment_folder = os.path.join(save_folder, single_experiment_name)\n",
    "    if not os.path.exists(save_single_experiment_folder):\n",
    "        os.mkdir(save_single_experiment_folder)\n",
    "    save_vis_folder = os.path.join(save_single_experiment_folder, 'vis')\n",
    "    if not os.path.exists(save_vis_folder):\n",
    "        os.makedirs(save_vis_folder)\n",
    "        print(\"makedirs {}\".format(save_vis_folder))\n",
    "    save_weight_path = os.path.join(save_single_experiment_folder, \"best_tr{}_val{}.pth\".format(num_list[0], num_list[1]))\n",
    "    results_save_path = os.path.join(save_single_experiment_folder, 'result_tr{}_val{}.txt'.format(num_list[0], num_list[1]))\n",
    "    predict_save_path = os.path.join(save_single_experiment_folder, 'pred_vis_tr{}_val{}.png'.format(num_list[0], num_list[1]))\n",
    "    gt_save_path = os.path.join(save_single_experiment_folder, 'gt_vis_tr{}_val{}.png'.format(num_list[0], num_list[1]))\n",
    "\n",
    "    train_data_index, val_data_index, test_data_index, all_data_index = data_load_operate.sampling(ratio_list,num_list,gt_reshape,class_count,flag_list[0])\n",
    "    index = (train_data_index, val_data_index, test_data_index)\n",
    "    train_label, val_label, test_label = data_load_operate.generate_image_iter(data, height, width, gt_reshape, index)\n",
    "\n",
    "    #建立模型\n",
    "    model = MambaHSI_NEW(in_channels=channels,num_classes=class_count,hidden_dim=128).to(device)\n",
    "    model.train()\n",
    "    model.low_channel_160_128.set_qconfig()\n",
    "    model.low_channel_128_128.set_qconfig()\n",
    "    torch.ao.quantization.prepare_qat(model, inplace=True)\n",
    "    if args.exp_name == \"RESULT_INT8_Conv_FP16_Mamba\":\n",
    "        model = change_model_high_mamba_float16(model) \n",
    "    logger.info(paras_dict)\n",
    "    logger.info(model)\n",
    "    \n",
    "    x = transform(np.array(img))#转化为张量\n",
    "    x = x.unsqueeze(0).float().to(device)\n",
    "    \n",
    "    train_label = train_label.to(device)\n",
    "    test_label = test_label.to(device)\n",
    "    val_label = val_label.to(device)\n",
    "\n",
    "    # ############################################\n",
    "    # val_label = test_label\n",
    "    # ############################################\n",
    "    train_loss_list = [100]\n",
    "    train_acc_list = [0]\n",
    "    val_loss_list = [100]\n",
    "    val_acc_list = [0]\n",
    "    if args.exp_name == \"RESULT_INT8_Conv\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,)\n",
    "    else:\n",
    "        optimizer = HybridOptimizer(model)\n",
    "    logger.info(optimizer)\n",
    "    best_loss = 99999\n",
    "\n",
    "\n",
    "    if record_computecost:#计算运算成本\n",
    "        model.eval()\n",
    "        flops, macs1, para = calculate_flops(model=model,\n",
    "                                             input_shape=(1, x.shape[1], x.shape[2], x.shape[3]), )\n",
    "        logger.info(\"para:{}\\n,flops:{}\".format(para, flops))#FLOPs\t浮点运算次数 (Floating Point Operations)，衡量模型计算复杂度\n",
    "                                                             #MACs\t乘加运算次数 (Multiply-Accumulate Operations)，硬件性能参考指标\n",
    "                                                             #Parameters\t模型参数量，决定模型大小和内存占用\n",
    "\n",
    "    tic1 = time.perf_counter()#记录开始时间\n",
    "    best_val_acc = 0\n",
    "\n",
    "    \n",
    "    for epoch in range(max_epoch):#全图进行输入，对大数据从高度进行切分\n",
    "        y_train = train_label.unsqueeze(0)\n",
    "        train_acc_sum, trained_samples_counter = 0.0, 0\n",
    "        batch_counter, train_loss_sum = 0, 0\n",
    "        time_epoch = time.time()\n",
    "        loss_dict = {}\n",
    "    \n",
    "        model.train()\n",
    "    \n",
    "        if split_image:#对汉川，休斯顿从图的宽进行切片，从中间切\n",
    "            x_part1 = x[:, :, :x.shape[2] // 2+5, :]\n",
    "            y_part1 = y_train[:,:x.shape[2] // 2+5,:]\n",
    "            x_part2 = x[:, :, x.shape[2] // 2 - 5: , :]\n",
    "            y_part2 = y_train[:,x.shape[2] // 2 - 5:,:]\n",
    "            \n",
    "            y_pred_part1 = model(x_part1)\n",
    "            ls1 = head_loss(loss_func,y_pred_part1, y_part1.long())#计算损失值\n",
    "            optimizer.zero_grad()\n",
    "            ls1.backward()\n",
    "            optimizer.step()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "            y_pred_part2 = model(x_part2)\n",
    "            ls2 = head_loss(loss_func,y_pred_part2, y_part2.long())\n",
    "            optimizer.zero_grad()\n",
    "            ls2.backward()\n",
    "            optimizer.step()\n",
    "            torch.cuda.empty_cache()\n",
    "            logger.info('Iter:{}|loss:{}'.format(epoch, (ls1 + ls2).detach().cpu().numpy()))\n",
    "    \n",
    "        else:\n",
    "            try:\n",
    "                y_pred = model(x)\n",
    "                ls = head_loss(loss_func,y_pred, y_train.long())\n",
    "                optimizer.zero_grad()\n",
    "                ls.backward()\n",
    "                optimizer.step()\n",
    "                logger.info('Iter:{}|loss:{}'.format(epoch, ls.detach().cpu().numpy()))\n",
    "            except:\n",
    "                optimizer.zero_grad()\n",
    "                torch.cuda.empty_cache()\n",
    "                split_image=True\n",
    "                x_part1 = x[:, :, :x.shape[2] // 2 + 5, :]\n",
    "                y_part1 = y_train[:, :x.shape[2] // 2 + 5, :]\n",
    "                x_part2 = x[:, :, x.shape[2] // 2 - 5:, :]\n",
    "                y_part2 = y_train[:, x.shape[2] // 2 - 5:, :]\n",
    "    \n",
    "                y_pred_part1 = model(x_part1)\n",
    "                ls1 = head_loss(loss_func, y_pred_part1, y_part1.long())\n",
    "                optimizer.zero_grad()\n",
    "                ls1.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                y_pred_part2 = model(x_part2)\n",
    "                ls2 = head_loss(loss_func, y_pred_part2, y_part2.long())\n",
    "                optimizer.zero_grad()\n",
    "                ls2.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                logger.info('Iter:{}|loss:{}'.format(epoch, (ls1 + ls2).detach().cpu().numpy()))\n",
    "        torch.cuda.empty_cache()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            evaluator.reset()\n",
    "            # output_val = net(x)\n",
    "            output_val = model(x)\n",
    "            y_val = val_label.unsqueeze(0)\n",
    "            seg_logits = resize(input=output_val,\n",
    "                                size=y_val.shape[1:],\n",
    "                                mode='bilinear',\n",
    "                                align_corners=True)\n",
    "            predict = torch.argmax(seg_logits,dim=1).cpu().numpy()#dim是维度，这里就是沿着第一个维度取最大值的索引，并且去掉这个维度\n",
    "            Y_val_np = val_label.cpu().numpy()\n",
    "            Y_val_255 = np.where(Y_val_np==-1,255,Y_val_np)#将值为-1的替换为255\n",
    "            evaluator.add_batch(np.expand_dims(Y_val_255,axis=0),predict)\n",
    "            OA = evaluator.Pixel_Accuracy()\n",
    "            mIOU, IOU = evaluator.Mean_Intersection_over_Union()\n",
    "            mAcc, Acc = evaluator.Pixel_Accuracy_Class()\n",
    "            Kappa = evaluator.Kappa()\n",
    "            \n",
    "            logger.info('Evaluate {}|OA:{}|MACC:{}|Kappa:{}|MIOU:{}|IOU:{}|ACC:{}'.format(epoch, OA,mAcc,Kappa,mIOU,IOU,Acc))\n",
    "            # save weight\n",
    "            if OA>=best_val_acc:\n",
    "                best_epoch = epoch + 1\n",
    "                best_val_acc = OA\n",
    "                torch.save(model.state_dict(), save_weight_path)\n",
    "            if (epoch+1)%50==0:\n",
    "                save_single_predict_path = os.path.join(save_vis_folder,'predict_{}.png'.format(str(epoch+1)))\n",
    "                save_single_gt_path = os.path.join(save_vis_folder,'gt.png')\n",
    "                vis_a_image(gt,predict,save_single_predict_path, save_single_gt_path)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    logger.info(\"\\n\\n====================Starting evaluation for testing set.========================\\n\")\n",
    "    print(\"量化模型转化\")\n",
    "    model.eval()\n",
    "    torch.ao.quantization.convert(model, inplace=True)\n",
    "    print(\"量化模型转化成功\")\n",
    "    pred_test = []\n",
    "    # 开始计时\n",
    "    \n",
    "    # load_weight_path = save_weight_path\n",
    "    # model.update_params = None\n",
    "    # # best_net = copy.deepcopy(net)\n",
    "    # best_model = MambaHSI_NEW(in_channels=channels, num_classes=class_count, hidden_dim=128)\n",
    "\n",
    "    # best_model.to(device)\n",
    "    # best_model.load_state_dict(torch.load(load_weight_path))\n",
    "    # best_model.eval()\n",
    "    test_evaluator = Evaluator(num_class=class_count)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_evaluator.reset()\n",
    "        start_time = time.time()\n",
    "        output_test = model(x)\n",
    "        end_time = time.time()\n",
    "        y_test = test_label.unsqueeze(0)\n",
    "        seg_logits_test = resize(input=output_test,\n",
    "                            size=y_test.shape[1:],\n",
    "                            mode='bilinear',\n",
    "                            align_corners=True)\n",
    "        predict_test = torch.argmax(seg_logits_test, dim=1).cpu().numpy()\n",
    "        Y_test_np = test_label.cpu().numpy()\n",
    "        Y_test_255 = np.where(Y_test_np == -1, 255, Y_test_np)\n",
    "        test_evaluator.add_batch(np.expand_dims(Y_test_255, axis=0), predict_test)\n",
    "        OA_test = test_evaluator.Pixel_Accuracy()\n",
    "        mIOU_test, IOU_test = test_evaluator.Mean_Intersection_over_Union()\n",
    "        mAcc_test, Acc_test = test_evaluator.Pixel_Accuracy_Class()\n",
    "        Kappa_test = evaluator.Kappa()\n",
    "        logger.info('Test {}|OA:{}|MACC:{}|Kappa:{}|MIOU:{}|IOU:{}|ACC:{}'.format(epoch, OA_test, mAcc_test, Kappa_test, mIOU_test, IOU_test,\n",
    "                                                                                Acc_test))\n",
    "        vis_a_image(gt, predict_test, predict_save_path, gt_save_path)   \n",
    "    \n",
    "    # 计算运行时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(elapsed_time)\n",
    "    f = open(results_save_path, 'a+')\n",
    "    str_results = '\\n======================' \\\n",
    "                  + \" exp_idx=\" + str(0) \\\n",
    "                  + \" seed=\" + str(0) \\\n",
    "                  + \" learning rate=\" + str(learning_rate) \\\n",
    "                  + \" epochs=\" + str(max_epoch) \\\n",
    "                  + \" train ratio=\" + str(ratio_list[0]) \\\n",
    "                  + \" val ratio=\" + str(ratio_list[1]) \\\n",
    "                  + \" ======================\" \\\n",
    "                  + \"\\nOA=\" + str(OA_test) \\\n",
    "                  + \"\\nAA=\" + str(mAcc_test) \\\n",
    "                  + '\\nkpp=' + str(Kappa_test) \\\n",
    "                  + '\\nmIOU_test:' + str(mIOU_test) \\\n",
    "                  + \"\\nIOU_test:\" + str(IOU_test) \\\n",
    "                  + \"\\nAcc_test:\" + str(Acc_test) + \"\\n\"\n",
    "    logger.info(str_results)\n",
    "    f.write(str_results)\n",
    "    f.close()\n",
    "\n",
    "    OA_ALL.append(OA_test)\n",
    "    AA_ALL.append(mAcc_test)\n",
    "    KPP_ALL.append(Kappa_test)\n",
    "    EACH_ACC_ALL.append(Acc_test)\n",
    "    Test_Time_ALL.append(elapsed_time)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "#十轮实验结束汇总    \n",
    "OA_ALL = np.array(OA_ALL)\n",
    "AA_ALL = np.array(AA_ALL)\n",
    "KPP_ALL = np.array(KPP_ALL)\n",
    "EACH_ACC_ALL = np.array(EACH_ACC_ALL)\n",
    "Train_Time_ALL = np.array(Train_Time_ALL)\n",
    "Test_Time_ALL = np.array(Test_Time_ALL)\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "logger.info(\"\\n====================Mean result of {} times runs =========================\".format(len(seed_list)))\n",
    "logger.info('List of OA:', list(OA_ALL))\n",
    "logger.info('List of AA:', list(AA_ALL))\n",
    "logger.info('List of KPP:', list(KPP_ALL))\n",
    "logger.info('OA=', round(np.mean(OA_ALL) * 100, 2), '+-', round(np.std(OA_ALL) * 100, 2))\n",
    "logger.info('AA=', round(np.mean(AA_ALL) * 100, 2), '+-', round(np.std(AA_ALL) * 100, 2))\n",
    "logger.info('Kpp=', round(np.mean(KPP_ALL) * 100, 2), '+-', round(np.std(KPP_ALL) * 100, 2))\n",
    "logger.info('Acc per class=', np.round(np.mean(EACH_ACC_ALL, 0) * 100, decimals=2), '+-',\n",
    "      np.round(np.std(EACH_ACC_ALL, 0) * 100, decimals=2))\n",
    "\n",
    "logger.info(\"Average training time=\", round(np.mean(Train_Time_ALL), 2), '+-', round(np.std(Train_Time_ALL), 3))\n",
    "logger.info(\"Average testing time=\", round(np.mean(Test_Time_ALL) * 1000, 2), '+-',round(np.std(Test_Time_ALL) * 1000, 3))\n",
    "\n",
    "# Output infors\n",
    "mean_result_path = os.path.join(save_folder,'mean_result.txt')\n",
    "f = open(mean_result_path, 'w')\n",
    "str_results = '\\n\\n***************Mean result of ' + str(len(seed_list)) + 'times runs ********************' \\\n",
    "              + '\\nList of OA:' + str(list(OA_ALL)) \\\n",
    "              + '\\nList of AA:' + str(list(AA_ALL)) \\\n",
    "              + '\\nList of KPP:' + str(list(KPP_ALL)) \\\n",
    "              + '\\nOA=' + str(round(np.mean(OA_ALL) * 100, 2)) + '+-' + str(round(np.std(OA_ALL) * 100, 2)) \\\n",
    "              + '\\nAA=' + str(round(np.mean(AA_ALL) * 100, 2)) + '+-' + str(round(np.std(AA_ALL) * 100, 2)) \\\n",
    "              + '\\nKpp=' + str(round(np.mean(KPP_ALL) * 100, 2)) + '+-' + str(\n",
    "    round(np.std(KPP_ALL) * 100, 2)) \\\n",
    "              + '\\nAcc per class=\\n' + str(np.round(np.mean(EACH_ACC_ALL, 0) * 100, 2)) + '+-' + str(\n",
    "    np.round(np.std(EACH_ACC_ALL, 0) * 100, 2)) \\\n",
    "              + \"\\nAverage training time=\" + str(\n",
    "    np.round(np.mean(Train_Time_ALL), decimals=2)) + '+-' + str(\n",
    "    np.round(np.std(Train_Time_ALL), decimals=3)) \\\n",
    "              + \"\\nAverage testing time=\" + str(\n",
    "    np.round(np.mean(Test_Time_ALL) * 1000, decimals=2)) + '+-' + str(\n",
    "    np.round(np.std(Test_Time_ALL) * 100, decimals=3))\n",
    "f.write(str_results)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baff847b-fd4a-4168-9f27-a0e6171c7dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.3964])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Time_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc60bdef-468e-43d0-bfc8-8e3c039b0d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5580410957336426\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result = model(x)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6eee300-295f-4363-a63a-23ac78cf048b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0|OA:0.8891782474989295|MACC:0.9093696409386913|Kappa:0.9|MIOU:0.7571869566211711|IOU:[0.8445 0.5297 0.7418 0.7523 0.698  0.6165 0.7331 0.8234 0.5961 0.8961\n",
      " 0.9276 0.8766 0.5824 0.7908 0.7852 0.9208]|ACC:[0.879  0.5546 0.8407 1.     1.     0.927  0.9405 0.8662 0.9661 0.9378\n",
      " 0.9766 0.9978 0.7937 0.9451 0.9772 0.9476]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_evaluator.reset()\n",
    "    output_test = model(x)\n",
    "\n",
    "    y_test = test_label.unsqueeze(0)\n",
    "    seg_logits_test = resize(input=output_test,\n",
    "                        size=y_test.shape[1:],\n",
    "                        mode='bilinear',\n",
    "                        align_corners=True)\n",
    "    predict_test = torch.argmax(seg_logits_test, dim=1).cpu().numpy()\n",
    "    Y_test_np = test_label.cpu().numpy()\n",
    "    Y_test_255 = np.where(Y_test_np == -1, 255, Y_test_np)\n",
    "    test_evaluator.add_batch(np.expand_dims(Y_test_255, axis=0), predict_test)\n",
    "    OA_test = test_evaluator.Pixel_Accuracy()\n",
    "    mIOU_test, IOU_test = test_evaluator.Mean_Intersection_over_Union()\n",
    "    mAcc_test, Acc_test = test_evaluator.Pixel_Accuracy_Class()\n",
    "    Kappa_test = evaluator.Kappa()\n",
    "    print('Test {}|OA:{}|MACC:{}|Kappa:{}|MIOU:{}|IOU:{}|ACC:{}'.format(0, OA_test, mAcc_test, Kappa_test, mIOU_test, IOU_test,\n",
    "                                                                            Acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f8fd60-6ef2-4ed4-9944-d0b5d5e2f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model_int8.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5d882b2-4202-4e85-a641-76d215ec0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_int8_dict.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64c02ec4-bc90-4b0e-940f-388526a59dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_memory(model, input_shape):\n",
    "    # 初始化\n",
    "    torch.cuda.empty_cache()\n",
    "    model = model.to('cuda')\n",
    "    \n",
    "    # 预热\n",
    "    _ = model(input_shape)\n",
    "    \n",
    "    # 内存基准\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    start_mem = torch.cuda.memory_allocated()\n",
    "    \n",
    "    # 前向传播\n",
    "    output = model(input_shape)\n",
    "    \n",
    "    # 反向传播（如需）\n",
    "    # loss = output.sum()\n",
    "    # loss.backward()\n",
    "    \n",
    "    # 计算峰值\n",
    "    peak_mem = torch.cuda.max_memory_allocated()\n",
    "    del output\n",
    "    return (peak_mem - start_mem) / 1024**3  # 转换为 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84f0a190-56fa-41ef-8453-a623fabdbef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model B 峰值内存: 2.522 GB\n"
     ]
    }
   ],
   "source": [
    "model_b_mem = measure_memory(model,x)\n",
    "\n",
    "# print(f\"Model A 峰值内存: {model_a_mem:.3f} GB\")\n",
    "print(f\"Model B 峰值内存: {model_b_mem:.3f} GB\")\n",
    "# print(f\"内存差异: {(model_b_mem - model_a_mem)/model_a_mem*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3311c687-5b9d-4c6e-b953-fb369a7a61df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  189.97 K\n",
      "fwd MACs:                                                               51.55 GMACs\n",
      "fwd FLOPs:                                                              105.25 GFLOPS\n",
      "fwd+bwd MACs:                                                           154.66 GMACs\n",
      "fwd+bwd FLOPs:                                                          315.74 GFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "MambaHSI_NEW(\n",
      "  189.97 K = 100% Params, 51.55 GMACs = 100% MACs, 105.25 GFLOPS = 100% FLOPs\n",
      "  (quant): QuantStub(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  (dequant): DeQuantStub(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  (patch_embedding): Sequential(\n",
      "    18.82 K = 9.9% Params, 12.25 GMACs = 23.77% MACs, 25.1 GFLOPS = 23.85% FLOPs\n",
      "    (0): Conv2d(18.56 K = 9.77% Params, 12.25 GMACs = 23.77% MACs, 24.59 GFLOPS = 23.37% FLOPs, 144, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): GroupNorm(256 = 0.13% Params, 0 MACs = 0% MACs, 425.5 MFLOPS = 0.4% FLOPs, 4, 128, eps=1e-05, affine=True)\n",
      "    (2): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 85.1 MFLOPS = 0.08% FLOPs)\n",
      "  )\n",
      "  (high_channel_128_32): Sequential(\n",
      "    4.19 K = 2.21% Params, 2.72 GMACs = 5.28% MACs, 5.6 GFLOPS = 5.32% FLOPs\n",
      "    (0): Conv2d(4.13 K = 2.17% Params, 2.72 GMACs = 5.28% MACs, 5.47 GFLOPS = 5.2% FLOPs, 128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): GroupNorm(64 = 0.03% Params, 0 MACs = 0% MACs, 106.38 MFLOPS = 0.1% FLOPs, 4, 32, eps=1e-05, affine=True)\n",
      "    (2): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 21.28 MFLOPS = 0.02% FLOPs)\n",
      "  )\n",
      "  (high_channel_160_32): Sequential(\n",
      "    5.22 K = 2.75% Params, 1.06 GMACs = 2.06% MACs, 2.17 GFLOPS = 2.06% FLOPs\n",
      "    (0): Conv2d(5.15 K = 2.71% Params, 1.06 GMACs = 2.06% MACs, 2.13 GFLOPS = 2.02% FLOPs, 160, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): GroupNorm(64 = 0.03% Params, 0 MACs = 0% MACs, 33.13 MFLOPS = 0.03% FLOPs, 4, 32, eps=1e-05, affine=True)\n",
      "    (2): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 6.63 MFLOPS = 0.01% FLOPs)\n",
      "  )\n",
      "  (low_channel_160_128): Low_Model(\n",
      "    0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs\n",
      "    (quant): Quantize(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, scale=tensor([0.0445], device='cuda:0'), zero_point=tensor([0], device='cuda:0'), dtype=torch.qint8)\n",
      "    (conv): QuantizedConv2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 160, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.019526412710547447, zero_point=0)\n",
      "    (dequant): DeQuantize(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (low_channel_160_128_fin): Sequential(\n",
      "    256 = 0.13% Params, 0 MACs = 0% MACs, 159.02 MFLOPS = 0.15% FLOPs\n",
      "    (0): GroupNorm(256 = 0.13% Params, 0 MACs = 0% MACs, 132.52 MFLOPS = 0.13% FLOPs, 4, 128, eps=1e-05, affine=True)\n",
      "    (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 26.5 MFLOPS = 0.03% FLOPs)\n",
      "  )\n",
      "  (low_channel_128_128): Low_Model(\n",
      "    0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs\n",
      "    (quant): Quantize(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, scale=tensor([0.0442], device='cuda:0'), zero_point=tensor([0], device='cuda:0'), dtype=torch.qint8)\n",
      "    (conv): QuantizedConv2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 128, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.016305984929203987, zero_point=0)\n",
      "    (dequant): DeQuantize(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (low_channel_128_128_fin): Sequential(\n",
      "    256 = 0.13% Params, 0 MACs = 0% MACs, 744.12 MFLOPS = 0.71% FLOPs\n",
      "    (0): GroupNorm(256 = 0.13% Params, 0 MACs = 0% MACs, 531.52 MFLOPS = 0.51% FLOPs, 4, 128, eps=1e-05, affine=True)\n",
      "    (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 106.3 MFLOPS = 0.1% FLOPs)\n",
      "    (2): AvgPool2d(0 = 0% Params, 0 MACs = 0% MACs, 106.3 MFLOPS = 0.1% FLOPs, kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (decomp): SpectralDecomp(\n",
      "    225 = 0.12% Params, 26.6 GMACs = 51.6% MACs, 53.2 GFLOPS = 50.55% FLOPs\n",
      "    (gaussian_blur): Sequential(\n",
      "      225 = 0.12% Params, 26.6 GMACs = 51.6% MACs, 53.2 GFLOPS = 50.55% FLOPs\n",
      "      (0): ReflectionPad2d(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, (7, 7, 7, 7))\n",
      "      (1): Conv2d(225 = 0.12% Params, 26.6 GMACs = 51.6% MACs, 53.2 GFLOPS = 50.55% FLOPs, 1, 1, kernel_size=(15, 15), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (high_mamba): Sequential(\n",
      "    11.35 K = 5.97% Params, 5.69 GMACs = 11.03% MACs, 11.72 GFLOPS = 11.14% FLOPs\n",
      "    (0): BothMamba(\n",
      "      11.35 K = 5.97% Params, 5.69 GMACs = 11.03% MACs, 11.69 GFLOPS = 11.11% FLOPs\n",
      "      (softmax): Softmax(0 = 0% Params, 0 MACs = 0% MACs, 4 FLOPS = 0% FLOPs, dim=0)\n",
      "      (spa_mamba): SpaMamba(\n",
      "        9.98 K = 5.26% Params, 3.51 GMACs = 6.8% MACs, 7.18 GFLOPS = 6.82% FLOPs\n",
      "        (mamba): Mamba(\n",
      "          9.92 K = 5.22% Params, 3.51 GMACs = 6.8% MACs, 7.02 GFLOPS = 6.67% FLOPs\n",
      "          (in_proj): Linear(4.1 K = 2.16% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=32, out_features=128, bias=False)\n",
      "          (conv1d): Conv1d(320 = 0.17% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)\n",
      "          (act): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          (x_proj): Linear(2.18 K = 1.15% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=34, bias=False)\n",
      "          (dt_proj): Linear(192 = 0.1% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=2, out_features=64, bias=True)\n",
      "          (out_proj): Linear(2.05 K = 1.08% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=32, bias=False)\n",
      "        )\n",
      "        (proj): Sequential(\n",
      "          64 = 0.03% Params, 0 MACs = 0% MACs, 159.45 MFLOPS = 0.15% FLOPs\n",
      "          (0): GroupNorm(64 = 0.03% Params, 0 MACs = 0% MACs, 132.88 MFLOPS = 0.13% FLOPs, 4, 32, eps=1e-05, affine=True)\n",
      "          (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 26.58 MFLOPS = 0.03% FLOPs)\n",
      "        )\n",
      "      )\n",
      "      (spe_mamba): SpeMamba(\n",
      "        1.36 K = 0.72% Params, 2.18 GMACs = 4.23% MACs, 4.52 GFLOPS = 4.29% FLOPs\n",
      "        (mamba): Mamba(\n",
      "          1.3 K = 0.68% Params, 2.18 GMACs = 4.23% MACs, 4.36 GFLOPS = 4.14% FLOPs\n",
      "          (in_proj): Linear(256 = 0.13% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=8, out_features=32, bias=False)\n",
      "          (conv1d): Conv1d(80 = 0.04% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 16, 16, kernel_size=(4,), stride=(1,), padding=(3,), groups=16)\n",
      "          (act): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "          (x_proj): Linear(528 = 0.28% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=16, out_features=33, bias=False)\n",
      "          (dt_proj): Linear(32 = 0.02% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=1, out_features=16, bias=True)\n",
      "          (out_proj): Linear(128 = 0.07% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=16, out_features=8, bias=False)\n",
      "        )\n",
      "        (proj): Sequential(\n",
      "          64 = 0.03% Params, 0 MACs = 0% MACs, 159.45 MFLOPS = 0.15% FLOPs\n",
      "          (0): GroupNorm(64 = 0.03% Params, 0 MACs = 0% MACs, 132.88 MFLOPS = 0.13% FLOPs, 4, 32, eps=1e-05, affine=True)\n",
      "          (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 26.58 MFLOPS = 0.03% FLOPs)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): AvgPool2d(0 = 0% Params, 0 MACs = 0% MACs, 26.58 MFLOPS = 0.03% FLOPs, kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (high_mamba_finally): BothMamba(\n",
      "    11.35 K = 5.97% Params, 283.59 MMACs = 0.55% MACs, 583.08 MFLOPS = 0.55% FLOPs\n",
      "    (softmax): Softmax(0 = 0% Params, 0 MACs = 0% MACs, 2 FLOPS = 0% FLOPs, dim=0)\n",
      "    (spa_mamba): SpaMamba(\n",
      "      9.98 K = 5.26% Params, 174.92 MMACs = 0.34% MACs, 357.8 MFLOPS = 0.34% FLOPs\n",
      "      (mamba): Mamba(\n",
      "        9.92 K = 5.22% Params, 174.92 MMACs = 0.34% MACs, 349.85 MFLOPS = 0.33% FLOPs\n",
      "        (in_proj): Linear(4.1 K = 2.16% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=32, out_features=128, bias=False)\n",
      "        (conv1d): Conv1d(320 = 0.17% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)\n",
      "        (act): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        (x_proj): Linear(2.18 K = 1.15% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=34, bias=False)\n",
      "        (dt_proj): Linear(192 = 0.1% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=2, out_features=64, bias=True)\n",
      "        (out_proj): Linear(2.05 K = 1.08% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "      (proj): Sequential(\n",
      "        64 = 0.03% Params, 0 MACs = 0% MACs, 7.95 MFLOPS = 0.01% FLOPs\n",
      "        (0): GroupNorm(64 = 0.03% Params, 0 MACs = 0% MACs, 6.63 MFLOPS = 0.01% FLOPs, 4, 32, eps=1e-05, affine=True)\n",
      "        (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 1.33 MFLOPS = 0% FLOPs)\n",
      "      )\n",
      "    )\n",
      "    (spe_mamba): SpeMamba(\n",
      "      1.36 K = 0.72% Params, 108.67 MMACs = 0.21% MACs, 225.28 MFLOPS = 0.21% FLOPs\n",
      "      (mamba): Mamba(\n",
      "        1.3 K = 0.68% Params, 108.67 MMACs = 0.21% MACs, 217.33 MFLOPS = 0.21% FLOPs\n",
      "        (in_proj): Linear(256 = 0.13% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=8, out_features=32, bias=False)\n",
      "        (conv1d): Conv1d(80 = 0.04% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 16, 16, kernel_size=(4,), stride=(1,), padding=(3,), groups=16)\n",
      "        (act): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        (x_proj): Linear(528 = 0.28% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=16, out_features=33, bias=False)\n",
      "        (dt_proj): Linear(32 = 0.02% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=1, out_features=16, bias=True)\n",
      "        (out_proj): Linear(128 = 0.07% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=16, out_features=8, bias=False)\n",
      "      )\n",
      "      (proj): Sequential(\n",
      "        64 = 0.03% Params, 0 MACs = 0% MACs, 7.95 MFLOPS = 0.01% FLOPs\n",
      "        (0): GroupNorm(64 = 0.03% Params, 0 MACs = 0% MACs, 6.63 MFLOPS = 0.01% FLOPs, 4, 32, eps=1e-05, affine=True)\n",
      "        (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 1.33 MFLOPS = 0% FLOPs)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (low_mamba_finally): BothMamba(\n",
      "    126.91 K = 66.81% Params, 2.48 GMACs = 4.81% MACs, 5.03 GFLOPS = 4.77% FLOPs\n",
      "    (softmax): Softmax(0 = 0% Params, 0 MACs = 0% MACs, 2 FLOPS = 0% FLOPs, dim=0)\n",
      "    (spa_mamba): SpaMamba(\n",
      "      116.74 K = 61.45% Params, 1.78 GMACs = 3.45% MACs, 3.59 GFLOPS = 3.41% FLOPs\n",
      "      (mamba): Mamba(\n",
      "        116.48 K = 61.31% Params, 1.78 GMACs = 3.45% MACs, 3.56 GFLOPS = 3.38% FLOPs\n",
      "        (in_proj): Linear(65.54 K = 34.5% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=128, out_features=512, bias=False)\n",
      "        (conv1d): Conv1d(1.28 K = 0.67% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
      "        (act): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        (x_proj): Linear(10.24 K = 5.39% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=256, out_features=40, bias=False)\n",
      "        (dt_proj): Linear(2.3 K = 1.21% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=8, out_features=256, bias=True)\n",
      "        (out_proj): Linear(32.77 K = 17.25% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=256, out_features=128, bias=False)\n",
      "      )\n",
      "      (proj): Sequential(\n",
      "        256 = 0.13% Params, 0 MACs = 0% MACs, 31.8 MFLOPS = 0.03% FLOPs\n",
      "        (0): GroupNorm(256 = 0.13% Params, 0 MACs = 0% MACs, 26.5 MFLOPS = 0.03% FLOPs, 4, 128, eps=1e-05, affine=True)\n",
      "        (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 5.3 MFLOPS = 0.01% FLOPs)\n",
      "      )\n",
      "    )\n",
      "    (spe_mamba): SpeMamba(\n",
      "      10.18 K = 5.36% Params, 699.7 MMACs = 1.36% MACs, 1.43 GFLOPS = 1.36% FLOPs\n",
      "      (mamba): Mamba(\n",
      "        9.92 K = 5.22% Params, 699.7 MMACs = 1.36% MACs, 1.4 GFLOPS = 1.33% FLOPs\n",
      "        (in_proj): Linear(4.1 K = 2.16% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=32, out_features=128, bias=False)\n",
      "        (conv1d): Conv1d(320 = 0.17% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, 64, 64, kernel_size=(4,), stride=(1,), padding=(3,), groups=64)\n",
      "        (act): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "        (x_proj): Linear(2.18 K = 1.15% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=34, bias=False)\n",
      "        (dt_proj): Linear(192 = 0.1% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=2, out_features=64, bias=True)\n",
      "        (out_proj): Linear(2.05 K = 1.08% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs, in_features=64, out_features=32, bias=False)\n",
      "      )\n",
      "      (proj): Sequential(\n",
      "        256 = 0.13% Params, 0 MACs = 0% MACs, 31.8 MFLOPS = 0.03% FLOPs\n",
      "        (0): GroupNorm(256 = 0.13% Params, 0 MACs = 0% MACs, 26.5 MFLOPS = 0.03% FLOPs, 4, 128, eps=1e-05, affine=True)\n",
      "        (1): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 5.3 MFLOPS = 0.01% FLOPs)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (cls_head): Sequential(\n",
      "    11.41 K = 6% Params, 463.81 MMACs = 0.9% MACs, 946.8 MFLOPS = 0.9% FLOPs\n",
      "    (0): Conv2d(10.3 K = 5.42% Params, 424.06 MMACs = 0.82% MACs, 850.77 MFLOPS = 0.81% FLOPs, 160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): GroupNorm(128 = 0.07% Params, 0 MACs = 0% MACs, 13.25 MFLOPS = 0.01% FLOPs, 4, 64, eps=1e-05, affine=True)\n",
      "    (2): SiLU(0 = 0% Params, 0 MACs = 0% MACs, 2.65 MFLOPS = 0% FLOPs)\n",
      "    (3): Conv2d(975 = 0.51% Params, 39.76 MMACs = 0.08% MACs, 80.13 MFLOPS = 0.08% FLOPs, 64, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "para:189.97 K\n",
      ",flops:105.25 GFLOPS\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "flops, macs1, para = calculate_flops(model=model,\n",
    "                                     input_shape=(1, x.shape[1], x.shape[2], x.shape[3]), )\n",
    "print(\"para:{}\\n,flops:{}\".format(para, flops))#FLOPs\t浮点运算次数 (Floating Point Operations)，衡量模型计算复杂度\n",
    "                                                     #MACs\t乘加运算次数 (Multiply-Accumulate Operations)，硬件性能参考指标\n",
    "                                                     #Parameters\t模型参数量，决定模型大小和内存占用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c2015-21ec-46a4-b207-a6782e6733fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
